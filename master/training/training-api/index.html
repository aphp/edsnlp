<!DOCTYPE html>

<html class="no-js" lang="en"> <head><meta charset="utf-8"/><meta content="width=device-width,initial-scale=1" name="viewport"/><link href="../../data/converters/" rel="prev"/><link href="../loggers/" rel="next"/><link href="../../assets/logo/edsnlp.svg" rel="icon"/><meta content="mkdocs-1.6.1, mkdocs-material-9.7.1" name="generator"/><title>Training API - EDS-NLP</title><link href="../../assets/stylesheets/main.484c7ddc.min.css" rel="stylesheet"/><link href="../../assets/stylesheets/palette.ab4e12ef.min.css" rel="stylesheet"/><link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/><link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link href="../../assets/_mkdocstrings.css" rel="stylesheet"/><link href="../../override.css" rel="stylesheet"/><link href="../../assets/stylesheets/extra.css" rel="stylesheet"/><link href="../../clickable-code.css" rel="stylesheet"/><link href="../../cards.css" rel="stylesheet"/><link href="../../pret.css" rel="stylesheet"/><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="default" dir="ltr"> <input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/> <input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/> <label class="md-overlay" for="__drawer"></label> <div data-md-component="skip"> <a class="md-skip" href="#training-api"> Skip to content </a> </div> <div data-md-component="announce"> <aside class="md-banner"> <div class="md-banner__inner md-grid md-typeset"> <button aria-label="Don't show this again" class="md-banner__button md-icon"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg> </button> Check out the new <a href="../../tutorials/training-span-classifier">span classifier training tutorial</a> and the <a href="../../tutorials/hpc">Slurm tutorial</a> ! </div> <script>var el=document.querySelector("[data-md-component=announce]");if(el){var content=el.querySelector(".md-typeset");__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0)}</script> </aside> </div> <div data-md-color-scheme="default" data-md-component="outdated" hidden=""> </div> <header class="md-header md-header--shadow" data-md-component="header"> <nav aria-label="Header" class="md-header__inner md-grid"> <a aria-label="EDS-NLP" class="md-header__button md-logo" data-md-component="logo" href="../.." title="EDS-NLP"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg> </a> <label class="md-header__button md-icon" for="__drawer"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg> </label> <div class="md-header__title" data-md-component="header-title"> <div class="md-header__ellipsis"> <div class="md-header__topic"> <span class="md-ellipsis"> EDS-NLP </span> </div> <div class="md-header__topic" data-md-component="header-topic"> <span class="md-ellipsis"> Training API </span> </div> </div> </div> <form class="md-header__option" data-md-component="palette"> <input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_0" name="__palette" type="radio"/> <label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to dark mode"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg> </label> <input aria-label="Switch to light mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="" data-md-color-primary="indigo" data-md-color-scheme="slate" id="__palette_1" name="__palette" type="radio"/> <label class="md-header__button md-icon" for="__palette_0" hidden="" title="Switch to light mode"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for="__search"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg> </label> <div class="md-search" data-md-component="search" role="dialog"> <label class="md-search__overlay" for="__search"></label> <div class="md-search__inner" role="search"> <form class="md-search__form" name="search"> <input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/> <label class="md-search__icon md-icon" for="__search"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg> </label> <nav aria-label="Search" class="md-search__options"> <button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" title="Clear" type="reset"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg> </button> </nav> </form> <div class="md-search__output"> <div class="md-search__scrollwrap" data-md-scrollfix="" tabindex="0"> <div class="md-search-result" data-md-component="search-result"> <div class="md-search-result__meta"> Initializing search </div> <ol class="md-search-result__list" role="presentation"></ol> </div> </div> </div> </div> </div> <div class="md-header__source"> <a class="md-source" data-md-component="source" href="https://github.com/aphp/edsnlp" title="Go to repository"> <div class="md-source__icon md-icon"> <svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg> </div> <div class="md-source__repository"> aphp/edsnlp </div> </a> </div> </nav> </header> <div class="md-container" data-md-component="container"> <main class="md-main" data-md-component="main"> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation"> <div class="md-sidebar__scrollwrap"> <div class="md-sidebar__inner"> <nav aria-label="Navigation" class="md-nav md-nav--primary" data-md-level="0"> <label class="md-nav__title" for="__drawer"> <a aria-label="EDS-NLP" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="EDS-NLP"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg> </a> EDS-NLP </label> <div class="md-nav__source"> <a class="md-source" data-md-component="source" href="https://github.com/aphp/edsnlp" title="Go to repository"> <div class="md-source__icon md-icon"> <svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg> </div> <div class="md-source__repository"> aphp/edsnlp </div> </a> </div> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../.."> <span class="md-ellipsis"> Getting started </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="https://aphp.github.io/edsnlp/demo" target="_blank"> <span class="md-ellipsis"> Demo </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class="md-nav__link" href="../../tutorials/"> <span class="md-ellipsis"> Tutorials </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class="md-nav__link" href="../../pipes/"> <span class="md-ellipsis"> Pipes </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../tokenizers/"> <span class="md-ellipsis"> Tokenizers </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class="md-nav__link" href="../../data/"> <span class="md-ellipsis"> Data Connectors </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input checked="" class="md-nav__toggle md-toggle" id="__nav_7" type="checkbox"/> <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0"> <span class="md-ellipsis"> Training </span> <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded="true" aria-labelledby="__nav_7_label" class="md-nav" data-md-level="1"> <label class="md-nav__title" for="__nav_7"> <span class="md-nav__icon md-icon"></span> Training </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/> <label class="md-nav__link md-nav__link--active" for="__toc"> <span class="md-ellipsis"> Training API </span> <span class="md-nav__icon md-icon"></span> </label> <a class="md-nav__link md-nav__link--active" href="./"> <span class="md-ellipsis"> Training API </span> </a> <nav aria-label="Table of contents" class="md-nav md-nav--secondary"> <label class="md-nav__title" for="__toc"> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="#how-it-works"> <span class="md-ellipsis"> How it works </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#tutorials-and-examples"> <span class="md-ellipsis"> Tutorials and examples </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#edsnlp.training.trainer.train"> <span class="md-ellipsis"> Parameters of edsnlp.train </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../loggers/"> <span class="md-ellipsis"> Loggers </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class="md-nav__link" href="../../concepts/pipeline/"> <span class="md-ellipsis"> Concepts </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class="md-nav__link" href="../../metrics/"> <span class="md-ellipsis"> Metrics </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class="md-nav__link" href="../../utilities/"> <span class="md-ellipsis"> Utilities </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class="md-nav__link" href="../../reference/edsnlp/"> <span class="md-ellipsis"> Code Reference </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../contributing/"> <span class="md-ellipsis"> Contributing to EDS-NLP </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../changelog/"> <span class="md-ellipsis"> Changelog </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc"> <div class="md-sidebar__scrollwrap"> <div class="md-sidebar__inner"> <nav aria-label="Table of contents" class="md-nav md-nav--secondary"> <label class="md-nav__title" for="__toc"> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="#how-it-works"> <span class="md-ellipsis"> How it works </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#tutorials-and-examples"> <span class="md-ellipsis"> Tutorials and examples </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#edsnlp.training.trainer.train"> <span class="md-ellipsis"> Parameters of edsnlp.train </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-content" data-md-component="content"> <article class="md-content__inner md-typeset"> <h1 id="training-api">Training API</h1> <p>Under the hood, EDS-NLP uses PyTorch to train and run deep-learning models. EDS-NLP acts as a sidekick to PyTorch, providing a set of tools to perform preprocessing, composition and evaluation. The trainable <a class="autorefs autorefs-internal" href="../../concepts/torch-component/#edsnlp.core.torch_component.TorchComponent" title="Torch Component"><code>TorchComponents</code></a> are actually PyTorch modules with a few extra methods to handle the feature preprocessing and postprocessing. Therefore, EDS-NLP is fully compatible with the PyTorch ecosystem.</p> <p>To build and train a deep learning model, you can either build a training script from scratch (check out the <a href="../../tutorials/make-a-training-script"><em>Make a training script</em></a> tutorial), or use the provided training API. The training API is designed to be flexible and can handle various types of models, including Named Entity Recognition (NER) models, span classifiers, and more. However, if you need more control over the training process, consider writing your own training script.</p> <p>EDS-NLP supports training models either from the command line or from a Python script or notebook, and switching between the two is relatively straightforward thanks to the use of <a href="https://aphp.github.io/confit/">Confit</a>.</p> <details class="note"> <summary>A word about Confit</summary> <p>EDS-NLP makes heavy use of <a href="https://aphp.github.io/confit/">Confit</a>, a configuration library that allows you call functions from Python or the CLI, and validate and optionally cast their arguments.</p> <p>The EDS-NLP function described on this page is the <code>train</code> function of the <code>edsnlp.train</code> module. When passing a dict to a type-hinted argument (either from a <code>config.yml</code> file, or by calling the function in Python), Confit will instantiate the correct class with the arguments provided in the dict. For instance, we pass a dict to the <code>train_data</code> parameter, which is actually type hinted as a <code>TrainingData</code>: this dict will actually be used as keyword arguments to instantiate this <code>TrainingData</code> object. You can also instantiate a <code>TrainingData</code> object directly and pass it to the function.</p> <p>You can also tell Confit specifically which class you want to instantiate by using the <code>@register_name = "name_of_the_registered_class"</code> key and value in a dict or config section. We make a heavy use of this mechanism to build pipeline architectures.</p> </details> <h2 id="how-it-works">How it works</h2> <p>To train a model with EDS-NLP, you need the following ingredients:</p> <ul> <li> <p><strong>Pipeline</strong>: a <a class="autorefs autorefs-internal" href="../../concepts/pipeline/#edsnlp.core.pipeline.Pipeline" title="Pipeline">pipeline</a> with at least one trainable component. Components that share parameters or that must be updated together are trained in the same phase.</p> </li> <li> <p><strong>Training streams</strong>: one or more streams of documents wrapped in a TrainingData object. Each of these specifies how to shuffle the stream, how to batch it with a stat expression such as <code>2000 words</code> or <code>16 spans</code>, whether to split batches into sub batches for gradient accumulation, and which components it feeds.</p> </li> <li> <p><strong>Validation streams</strong>: optional streams of documents used for periodic evaluation.</p> </li> <li> <p><strong>Scorer</strong>: a <a class="autorefs autorefs-internal" href="../../reference/edsnlp/training/trainer/#edsnlp.training.trainer.GenericScorer" title="GenericScorer">scorer</a> that defines the metrics to compute on the validation set. By default, it reports speed and uses autocast during scoring unless disabled.</p> </li> <li> <p><strong>Optimizer</strong>: an <a class="autorefs autorefs-internal" href="../../reference/edsnlp/training/optimizer/#edsnlp.training.optimizer.ScheduledOptimizer" title="ScheduledOptimizer">optimizer</a>. Defaults to AdamW with linear warmup and two groups of parameters, one for the transformer with lr 5•10^-5, and one for the rest of the model with lr 3•10^-4.</p> </li> <li> <p><strong>A bunch of hyperparameters</strong>: finally, the function expects various hyperparameters (most of them set to sensible defaults) to the function, such as <code>max_steps</code>, <code>seed</code>, <code>validation_interval</code>, <code>checkpoint_interval</code>, <code>grad_max_norm</code>, and more.</p> </li> </ul> <p>The training then proceeds in several steps:</p> <p><strong>Setup</strong> The function prepares the device with <a href="https://huggingface.co/docs/accelerate/index">Accelerate</a>, creates the output folders, materializes the validation set from the user-provided stream, and runs a post-initialization pass on the training data when requested. This <code>post_init</code> op let's the pipeline inspect the data before learning to adjust the number of heads depending on the labels encountered. Finally, the optimizer is instantiated.</p> <p><strong>Phases</strong> Training runs <strong>by phases</strong>. A phase groups components that should be optimized together because they share parameters (think for instance of a BERT shared between multiple models). During a phase, losses are computed for each of these "active" components at each step, and only their parameters are updated.</p> <p><strong>Data preparation</strong> Each TrainingData object turns its streams of documents into device ready batches. It optionally shuffles the stream, preprocess the documents for the active components, builds stat-aware batches (for instance, limiting the number of tokens per batch), optionally splits batches into sub batches for gradient accumulation, then converts everything into device-ready tensors. This can be done in parallel to the actual deep-learning work.</p> <p><strong>Optimization</strong> For every training step the function draws one batch from each training stream (in case there are more than one) and synchronizes statistics across processes (in case we're doing multi-GPU training) to keep supports and losses consistent. It runs forward passes for the phase components. When several components reuse the same intermediate features a cache avoids recomputation. Gradients are accumulated over sub batches.</p> <p><strong>Gradient safety</strong> Gradients are always clipped to <code>grad_max_norm</code>. Optionally the function tracks an exponential moving mean and variance of the gradient norm. If a spike is detected you can clip to the running mean or to a threshold or skip the update depending on <code>grad_dev_policy</code>. This protects training from rare extreme updates.</p> <p><strong>Validation and logging</strong> At regular intervals the scorer evaluates the pipeline on the validation documents. It isolates each task by copying docs and disabling unrelated pipes to avoid leakage. It reports throughput and metrics for NER and span attribute classifiers plus any custom metrics.</p> <p><strong>Checkpoints and output</strong> The model is saved on schedule and at the end in <code>output_dir/model-last</code> unless saving is disabled.</p> <h2 id="tutorials-and-examples">Tutorials and examples</h2> <div class="card-set" data-cards="1:4"><a class="card-content" href="../../tutorials/make-a-training-script"><p><span class="twemoji"><svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M288 0H128c-17.7 0-32 14.3-32 32s14.3 32 32 32v151.5L7.5 426.3C2.6 435 0 444.7 0 454.7 0 486.4 25.6 512 57.3 512h333.4c31.6 0 57.3-25.6 57.3-57.3 0-10-2.6-19.8-7.5-28.4L320 215.5V64c17.7 0 32-14.3 32-32S337.7 0 320 0zm-96 215.5V64h64v151.5c0 11.1 2.9 22.1 8.4 31.8L306 320H142l41.6-72.7c5.5-9.7 8.4-20.6 8.4-31.8"></path></svg></span> <strong>Writing a training script</strong></p><hr/><p>Learn how EDS-NLP handles training deep-neural networks, and how to write a training script on your own.</p></a><a class="card-content" href="../../tutorials/training-ner"><p><span class="twemoji"><svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M315 315 473.4 99.9l-29.3-29.3L229 229zm-187 5v-71.7c0-15.3 7.2-29.6 19.5-38.6L420.6 8.4C428 2.9 437 0 446.2 0c11.4 0 22.3 4.5 30.4 12.6l54.8 54.8c8.1 8.1 12.6 19 12.6 30.5 0 9.2-2.9 18.2-8.4 25.6l-201.2 273c-9 12.3-23.4 19.5-38.6 19.5h-71.7l-25.4 25.4c-12.5 12.5-32.8 12.5-45.3 0l-50.7-50.7c-12.5-12.5-12.5-32.8 0-45.3zM7 466.3l51.7-51.7 70.6 70.6-19.7 19.7c-4.5 4.5-10.6 7-17 7L24 512c-13.3 0-24-10.7-24-24v-4.7c0-6.4 2.5-12.5 7-17"></path></svg></span> <strong>Training a NER model</strong></p><hr/><p>Learn how to quickly train a NER model with <code>edsnlp.train</code>.</p></a><a class="card-content" href="../../tutorials/training-span-classifier"><p><span class="twemoji"><svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M256 512a256 256 0 1 1 0-512 256 256 0 1 1 0 512m118-366.3c-10.7-7.8-25.7-5.4-33.5 5.3L221.1 315.2 169 263.1c-9.4-9.4-24.6-9.4-33.9 0s-9.4 24.6 0 33.9l72 72c5 5 11.8 7.5 18.8 7s13.4-4.1 17.5-9.8l135.9-187c7.8-10.7 5.4-25.7-5.3-33.5"></path></svg></span> <strong>Training a Span Classifier model</strong></p><hr/><p>Learn how to quickly train a biopsy date classifier model model with <code>edsnlp.train</code>.</p></a><a class="card-content" href="../../tutorials/tuning"><p><span class="twemoji"><svg viewbox="0 0 640 512" xmlns="http://www.w3.org/2000/svg"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M415.9 210.5c12.2-3.3 25 2.5 30.5 13.8l18.6 37.6c10.3 1.4 20.4 4.2 29.9 8.1l35-23.3c10.5-7 24.4-5.6 33.3 3.3l19.2 19.2c8.9 8.9 10.3 22.9 3.3 33.3l-23.3 34.9c1.9 4.7 3.6 9.6 5 14.7s2.3 10.1 3 15.2l37.7 18.6c11.3 5.6 17.1 18.4 13.8 30.5l-7 26.2c-3.3 12.1-14.6 20.3-27.2 19.5l-42-2.7c-6.3 8.1-13.6 15.6-21.9 22l2.7 41.9c.8 12.6-7.4 24-19.5 27.2l-26.2 7c-12.2 3.3-24.9-2.5-30.5-13.8l-18.6-37.6c-10.3-1.4-20.4-4.2-29.9-8.1l-35 23.3c-10.5 7-24.4 5.6-33.3-3.3l-19.2-19.2c-8.9-8.9-10.3-22.8-3.3-33.3l23.3-35c-1.9-4.7-3.6-9.6-5-14.7s-2.3-10.2-3-15.2L288.6 382c-11.3-5.6-17-18.4-13.8-30.5l7-26.2c3.3-12.1 14.6-20.3 27.2-19.5l41.9 2.7c6.3-8.1 13.6-15.6 21.9-22l-2.7-41.8c-.8-12.6 7.4-24 19.5-27.2l26.2-7zM448.4 340a44 44 0 1 0 .1 88 44 44 0 1 0-.1-88M224.9-45.5l26.2 7c12.1 3.3 20.3 14.7 19.5 27.2l-2.7 41.8c8.3 6.4 15.6 13.8 21.9 22l42-2.7c12.5-.8 23.9 7.4 27.2 19.5l7 26.2c3.2 12.1-2.5 24.9-13.8 30.5l-37.7 18.6c-.7 5.1-1.7 10.2-3 15.2s-3.1 10-5 14.7l23.3 35c7 10.5 5.6 24.4-3.3 33.3L307.3 262c-8.9 8.9-22.8 10.3-33.3 3.3L239 242c-9.5 3.9-19.6 6.7-29.9 8.1l-18.6 37.6c-5.6 11.3-18.4 17-30.5 13.8l-26.2-7c-12.2-3.3-20.3-14.7-19.5-27.2l2.7-41.9c-8.3-6.4-15.6-13.8-21.9-22l-42 2.7c-12.5.8-23.9-7.4-27.2-19.5l-7-26.2c-3.2-12.1 2.5-24.9 13.8-30.5l37.7-18.6c.7-5.1 1.7-10.1 3-15.2 1.4-5.1 3-10 5-14.7L55.1 46.5c-7-10.5-5.6-24.4 3.3-33.3L77.6-6c8.9-8.9 22.8-10.3 33.3-3.3l35 23.3c9.5-3.9 19.6-6.7 29.9-8.1l18.6-37.6c5.6-11.3 18.3-17 30.5-13.8M192.4 84a44 44 0 1 0 0 88 44 44 0 1 0 0-88"></path></svg></span> <strong>Hyperparameter Tuning</strong></p><hr/><p>Learn how to tune hyperparameters of a model with <code>edsnlp.tune</code>.</p></a></div> <h2 id="edsnlp.training.trainer.train">Parameters of <code>edsnlp.train</code></h2> <p>Here are the parameters you can pass to the <code>train</code> function:</p> <div class="doc doc-object doc-function"> <div class="doc doc-contents first"> <table> <thead> <tr> <th><b>PARAMETER</b></th> <th><b>DESCRIPTION</b></th> </tr> </thead> <tbody> <tr> <td><code>nlp</code></td> <td class="doc-param-details"> <p>The pipeline that will be trained in place.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><a class="autorefs autorefs-internal" href="../../reference/edsnlp/core/pipeline/#edsnlp.core.pipeline.Pipeline" title="Pipeline (edsnlp.Pipeline)">Pipeline</a></code> </span> </p> </td> </tr> <tr> <td><code>train_data</code></td> <td class="doc-param-details"> <p>The training data. Can be a single <a class="autorefs autorefs-internal" href="../../reference/edsnlp/training/trainer/#edsnlp.training.trainer.TrainingData" title="TrainingData">TrainingData</a> object, a dict that will be cast or a list of these objects.</p> <details class="note"> <summary><code>TrainingData</code> object/dictionary</summary> <div class="doc doc-object doc-class"> <table> <thead> <tr> <th><b>PARAMETER</b></th> <th><b>DESCRIPTION</b></th> </tr> </thead> <tbody> <tr> <td><code>data</code></td> <td class="doc-param-details"> <p>The stream of documents to train on. The documents will be preprocessed and collated according to the pipeline's components.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><a class="autorefs autorefs-internal" href="../../concepts/inference/#edsnlp.core.stream.Stream" title="Streams (edsnlp.core.stream.Stream)">Stream</a></code> </span> </p> </td> </tr> <tr> <td><code>batch_size</code></td> <td class="doc-param-details"> <p>The batch size. Can be a batching expression like "2000 words", an int (number of documents), or a tuple (batch_size, batch_by). The batch_by argument should be a statistic produced by the pipes that will be trained. For instance, the <code><a href="../../pipes/trainable/embeddings/span_pooler/#edsnlp.pipes.trainable.embeddings.span_pooler.factory.create_component">eds.span_pooler</a></code> component produces a "spans" statistic, that can be used to produce batches of no more than 16 spans by setting batch_size to "16 spans".</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><a class="autorefs autorefs-internal" href="../../reference/edsnlp/utils/batching/#edsnlp.utils.batching.BatchSizeArg" title="BatchSizeArg (edsnlp.utils.batching.BatchSizeArg)">BatchSizeArg</a></code> </span> </p> </td> </tr> <tr> <td><code>shuffle</code></td> <td class="doc-param-details"> <p>The shuffle strategy. Can be "dataset" to shuffle the entire dataset (this can be memory-intensive for large file based datasets), "fragment" to shuffle the fragment-based datasets like parquet files, or a batching expression like "2000 words" to shuffle the dataset in chunks of 2000 words.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="typing_extensions.Literal">Literal</span>[False]]</code> </span> </p> </td> </tr> <tr> <td><code>sub_batch_size</code></td> <td class="doc-param-details"> <p>How to split each batch into sub-batches that will be fed to the model independently to accumulate gradients over. To split a batch of 8000 tokens into smaller batches of 1000 tokens each, just set this to "1000 tokens".</p> <p>You can also request a number of splits, like "4 splits", to split the batch into N parts each close to (but less than) batch_size / N.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" href="../../reference/edsnlp/utils/batching/#edsnlp.utils.batching.BatchSizeArg" title="BatchSizeArg (edsnlp.utils.batching.BatchSizeArg)">BatchSizeArg</a>]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> <tr> <td><code>pipe_names</code></td> <td class="doc-param-details"> <p>The names of the pipes that should be trained on this data. If None, defaults to all trainable pipes.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Optional">Optional</span>[<span title="edsnlp.utils.typing.AsList">AsList</span>[<span title="str">str</span>]]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> <tr> <td><code>post_init</code></td> <td class="doc-param-details"> <p>Whether to call the pipeline's post_init method with the data before training.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="bool">bool</span></code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>True</code> </span> </p> </td> </tr> </tbody> </table> </div></details> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="edsnlp.utils.typing.AsList">AsList</span>[<a class="autorefs autorefs-internal" href="../../reference/edsnlp/training/trainer/#edsnlp.training.trainer.TrainingData" title="TrainingData (edsnlp.training.trainer.TrainingData)">TrainingData</a>]</code> </span> </p> </td> </tr> <tr> <td><code>val_data</code></td> <td class="doc-param-details"> <p>The validation data. Can be a single Stream object or a list of Stream.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="edsnlp.utils.typing.AsList">AsList</span>[<a class="autorefs autorefs-internal" href="../../concepts/inference/#edsnlp.core.stream.Stream" title="Streams (edsnlp.core.stream.Stream)">Stream</a>]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>[]</code> </span> </p> </td> </tr> <tr> <td><code>seed</code></td> <td class="doc-param-details"> <p>The random seed</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="int">int</span></code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>42</code> </span> </p> </td> </tr> <tr> <td><code>max_steps</code></td> <td class="doc-param-details"> <p>The maximum number of training steps</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="int">int</span></code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>1000</code> </span> </p> </td> </tr> <tr> <td><code>optimizer</code></td> <td class="doc-param-details"> <p>The optimizer. If None, a default optimizer will be used.</p> <details class="note"> <summary><code>ScheduledOptimizer</code> object/dictionary</summary> <div class="doc doc-object doc-class"> <table> <thead> <tr> <th><b>PARAMETER</b></th> <th><b>DESCRIPTION</b></th> </tr> </thead> <tbody> <tr> <td><code>optim</code></td> <td class="doc-param-details"> <p>The optimizer to use. If a string (like "adamw") or a type to instantiate, the <code>module</code> and <code>groups</code> must be provided.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="typing.Type">Type</span>[<span title="torch.optim.Optimizer">Optimizer</span>], <span title="torch.optim.Optimizer">Optimizer</span>]</code> </span> </p> </td> </tr> <tr> <td><code>module</code></td> <td class="doc-param-details"> <p>The module to optimize. Usually the <code>nlp</code> pipeline object.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[<span title="edsnlp.core.PipelineProtocol">PipelineProtocol</span>, <span title="torch.nn.Module">Module</span>]]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> <tr> <td><code>total_steps</code></td> <td class="doc-param-details"> <p>The total number of steps, used for schedules.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Optional">Optional</span>[<span title="int">int</span>]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> <tr> <td><code>groups</code></td> <td class="doc-param-details"> <p>The groups to optimize. Each group is a dictionary containing:</p> <ul> <li>a regex <code>selector</code> key to match the parameter of that group by their names (as listed by <code>nlp.named_parameters()</code>)</li> <li>and several other keys that define the optimizer parameters for that group, such as <code>lr</code>, <code>weight_decay</code> etc. The value for these keys can be a <code>Schedule</code> instance or a simple value</li> <li>an <code>exclude</code> key that can be set to True to exclude parameters</li> </ul> <p>The matching is performed by running <code>regex.search(selector, name)</code> so you do not have to match the full name. Note that the order of the groups matters. If a parameter name matches multiple selectors, the configurations of these selectors are combined in reverse order (from the last matched selector to the first), allowing later selectors to complete options from earlier ones. If a selector contains <code>exclude=True</code>, any parameter matching it is excluded from optimization.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Optional">Optional</span>[<span title="typing.List">List</span>[<span title="Group">Group</span>]]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> </tbody> </table> </div></details> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Union">Union</span>[<a class="autorefs autorefs-external" href="https://aphp.github.io/confit/latest/reference/draft/#confit.draft.Draft" title="confit.Draft">Draft</a>[<a class="autorefs autorefs-internal" href="../../reference/edsnlp/training/optimizer/#edsnlp.training.optimizer.ScheduledOptimizer" title="ScheduledOptimizer (edsnlp.training.optimizer.ScheduledOptimizer)">ScheduledOptimizer</a>], <a class="autorefs autorefs-internal" href="../../reference/edsnlp/training/optimizer/#edsnlp.training.optimizer.ScheduledOptimizer" title="ScheduledOptimizer (edsnlp.training.optimizer.ScheduledOptimizer)">ScheduledOptimizer</a>, <span title="torch.optim.Optimizer">Optimizer</span>]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> <tr> <td><code>validation_interval</code></td> <td class="doc-param-details"> <p>The number of steps between each evaluation. Defaults to 1/10 of max_steps</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Optional">Optional</span>[<span title="int">int</span>]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> <tr> <td><code>checkpoint_interval</code></td> <td class="doc-param-details"> <p>The number of steps between each model save. Defaults to validation_interval</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Optional">Optional</span>[<span title="int">int</span>]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> <tr> <td><code>grad_max_norm</code></td> <td class="doc-param-details"> <p>The maximum gradient norm</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="float">float</span></code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>5.0</code> </span> </p> </td> </tr> <tr> <td><code>grad_dev_policy</code></td> <td class="doc-param-details"> <p>The policy to apply when a gradient spike is detected, ie. when the gradient norm is higher than the mean + std * grad_max_dev. Can be:</p> <ul> <li>"clip_mean": clip the gradients to the mean gradient norm</li> <li>"clip_threshold": clip the gradients to the mean + std * grad_max_dev</li> <li>"skip": skip the step</li> </ul> <p>These do not apply to <code>grad_max_norm</code> that is always enforced when it is not None, since <code>grad_max_norm</code> is not adaptive and would most likely prohibit the model from learning during the early stages of training when gradients are expected to be high.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Optional">Optional</span>[<span title="typing_extensions.Literal">Literal</span>['clip_mean', 'clip_threshold', 'skip']]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> <tr> <td><code>grad_ewm_window</code></td> <td class="doc-param-details"> <p>Approximately how many steps should we look back to compute the average gradient norm and variance to detect gradient deviation spikes.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="int">int</span></code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>100</code> </span> </p> </td> </tr> <tr> <td><code>grad_max_dev</code></td> <td class="doc-param-details"> <p>The threshold to apply to detect gradient spikes. A spike is detected when the value is higher than the mean + variance * threshold.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="float">float</span></code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>7.0</code> </span> </p> </td> </tr> <tr> <td><code>loss_scales</code></td> <td class="doc-param-details"> <p>The loss scales for each component (useful for multi-task learning)</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Dict">Dict</span>[<span title="str">str</span>, <span title="float">float</span>]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>{}</code> </span> </p> </td> </tr> <tr> <td><code>scorer</code></td> <td class="doc-param-details"> <p>How to score the model. Expects a <code>GenericScorer</code> object or a dict containing a mapping of metric names to metric objects.</p> <details class="note"> <summary><code>GenericScorer</code> object/dictionary</summary> <div class="doc doc-object doc-class"> <table> <thead> <tr> <th><b>PARAMETER</b></th> <th><b>DESCRIPTION</b></th> </tr> </thead> <tbody> <tr> <td><code>batch_size</code></td> <td class="doc-param-details"> <p>The batch size to use for scoring. Can be an int (number of documents) or a string (batching expression like "2000 words").</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Union">Union</span>[<span title="int">int</span>, <span title="str">str</span>]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>1</code> </span> </p> </td> </tr> <tr> <td><code>speed</code></td> <td class="doc-param-details"> <p>Whether to compute the model speed (words/documents per second)</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="bool">bool</span></code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>True</code> </span> </p> </td> </tr> <tr> <td><code>autocast</code></td> <td class="doc-param-details"> <p>Whether to use autocasting for mixed precision during the evaluation, defaults to True.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Union">Union</span>[<span title="bool">bool</span>, <span title="typing.Any">Any</span>]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> <tr> <td><code>metrics</code></td> <td class="doc-param-details"> <p>A keyword arguments mapping of metric names to metrics objects. See the <a href="../../metrics">metrics</a> documentation for more info.</p> <p> <span class="doc-param-default"> <b>DEFAULT:</b> <code>{}</code> </span> </p> </td> </tr> </tbody> </table> </div></details> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><a class="autorefs autorefs-internal" href="../../reference/edsnlp/training/trainer/#edsnlp.training.trainer.GenericScorer" title="GenericScorer (edsnlp.training.trainer.GenericScorer)">GenericScorer</a></code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code><a class="autorefs autorefs-internal" href="../../reference/edsnlp/training/trainer/#edsnlp.training.trainer.GenericScorer" title="GenericScorer (edsnlp.training.trainer.GenericScorer)">GenericScorer</a>()</code> </span> </p> </td> </tr> <tr> <td><code>num_workers</code></td> <td class="doc-param-details"> <p>The number of workers to use for preprocessing the data in parallel. Setting it to 0 means no parallelization : data is processed on the main thread which may induce latency slow down the training. To avoid this, a good practice consist in doing the preprocessing either before training or in parallel in a separate process. Because of how EDS-NLP handles stream multiprocessing, changing this value will affect the order of the documents in the produces batches. A stream [1, 2, 3, 4, 5, 6] split in batches of size 3 will produce:</p> <ul> <li>[1, 2, 3] and [4, 5, 6] with 1 worker</li> <li>[1, 3, 5] and [2, 4, 6] with 2 workers</li> </ul> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="int">int</span></code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>0</code> </span> </p> </td> </tr> <tr> <td><code>cpu</code></td> <td class="doc-param-details"> <p>Whether to use force training on CPU. On MacOS, this might be necessary to get around some <code>mps</code> backend issues.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="bool">bool</span></code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>False</code> </span> </p> </td> </tr> <tr> <td><code>mixed_precision</code></td> <td class="doc-param-details"> <p>The mixed precision mode. Can be "no", "fp16", "bf16" or "fp8".</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing_extensions.Literal">Literal</span>['no', 'fp16', 'bf16', 'fp8']</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>'no'</code> </span> </p> </td> </tr> <tr> <td><code>output_dir</code></td> <td class="doc-param-details"> <p>The output directory, which will contain a <code>model-last</code> directory with the last model, and a <code>train_metrics.json</code> file with the training metrics and stats.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Union">Union</span>[<span title="pathlib.Path">Path</span>, <span title="str">str</span>]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code><span title="pathlib.Path">Path</span>('artifacts')</code> </span> </p> </td> </tr> <tr> <td><code>output_model_dir</code></td> <td class="doc-param-details"> <p>The directory where to save the model. If None, defaults to <code>output_dir / "model-last"</code>.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[<span title="pathlib.Path">Path</span>, <span title="str">str</span>]]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> <tr> <td><code>save_model</code></td> <td class="doc-param-details"> <p>Whether to save the model or not. This can be useful if you are only interested in the metrics, but no the model, and want to avoid spending time dumping the model weights to the disk.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="bool">bool</span></code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>True</code> </span> </p> </td> </tr> <tr> <td><code>logger</code></td> <td class="doc-param-details"> <p>The logger to use. Can be a boolean to use the default loggers (rich and json), a list of logger names, or a list of logger objects.</p> <p>You can use huggingface accelerate integrated loggers (<code>tensorboard</code>, <code>wandb</code>, <code>comet_ml</code>, <code>aim</code>, <code>mlflow</code>, <code>clearml</code>, <code>dvclive</code>), or EDS-NLP simple loggers, or a combination of both:</p> <ul> <li><code>csv</code>: logs to a CSV file in <code>output_dir</code> (<code>artifacts/metrics.csv</code>)</li> <li><code>json</code>: logs to a JSON file in <code>output_dir</code> (<code>artifacts/metrics.json</code>)</li> <li><code>rich</code>: logs to a rich table in the terminal</li> </ul> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Union">Union</span>[<span title="bool">bool</span>, <span title="edsnlp.utils.typing.AsList">AsList</span>[<span title="typing.Union">Union</span>[<span title="str">str</span>, <span title="accelerate.tracking.GeneralTracker">GeneralTracker</span>, <a class="autorefs autorefs-external" href="https://aphp.github.io/confit/latest/reference/draft/#confit.draft.Draft" title="confit.Draft">Draft</a>[<span title="accelerate.tracking.GeneralTracker">GeneralTracker</span>]]]]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>True</code> </span> </p> </td> </tr> <tr> <td><code>log_weight_grads</code></td> <td class="doc-param-details"> <p>Whether to log the weight gradients during training.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="bool">bool</span></code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>False</code> </span> </p> </td> </tr> <tr> <td><code>on_validation_callback</code></td> <td class="doc-param-details"> <p>A callback function invoked during validation steps to handle custom logic.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Optional">Optional</span>[<span title="typing.Callable">Callable</span>[[<span title="typing.Dict">Dict</span>], None]]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> <tr> <td><code>project_name</code></td> <td class="doc-param-details"> <p>The project name, used to group experiments in some loggers. If None, defaults to the path of the config file, relative to the home directory, with slashes replaced by double underscores.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="str">str</span></code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> <tr> <td><code>kwargs</code></td> <td class="doc-param-details"> <p>Additional keyword arguments.</p> <p> <span class="doc-param-default"> <b>DEFAULT:</b> <code>{}</code> </span> </p> </td> </tr> </tbody> </table> </div> </div> <div class="footnote"><hr/><ol></ol></div> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button class="md-top md-icon" data-md-component="top" hidden="" type="button"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg> Back to top </button> </main> <footer class="md-footer"> <nav aria-label="Footer" class="md-footer__inner md-grid"> <a aria-label="Previous: Converters" class="md-footer__link md-footer__link--prev" href="../../data/converters/"> <div class="md-footer__button md-icon"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg> </div> <div class="md-footer__title"> <span class="md-footer__direction"> Previous </span> <div class="md-ellipsis"> Converters </div> </div> </a> <a aria-label="Next: Loggers" class="md-footer__link md-footer__link--next" href="../loggers/"> <div class="md-footer__title"> <span class="md-footer__direction"> Next </span> <div class="md-ellipsis"> Loggers </div> </div> <div class="md-footer__button md-icon"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class="md-copyright"> <div class="md-copyright__highlight"> Copyright © 2025 – Assistance Publique - Hôpitaux de Paris </div> Made with <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank"> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class="md-dialog" data-md-component="dialog"> <div class="md-dialog__inner md-typeset"></div> </div> <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.tracking", "navigation.instant", "navigation.indexes", "navigation.prune", "navigation.top", "navigation.footer", "content.code.annotate", "content.code.copy", "announce.dismiss"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "latest", "provider": "mike"}}</script> <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script> <script pret-head-scripts=""></script> </body> </html>