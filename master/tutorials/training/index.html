<!DOCTYPE html>
<html class="no-js" lang="en"> <head><meta charset="utf-8"/><meta content="width=device-width,initial-scale=1" name="viewport"/><link href="../make-a-training-script/" rel="prev"/><link href="../tuning/" rel="next"/><link href="../../assets/logo/edsnlp.svg" rel="icon"/><meta content="mkdocs-1.5.3, mkdocs-material-9.2.8" name="generator"/><title>Training API - EDS-NLP</title><link href="../../assets/stylesheets/main.046329b4.min.css" rel="stylesheet"/><link href="../../assets/stylesheets/palette.85d0ee34.min.css" rel="stylesheet"/><link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/><link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link href="../../assets/_mkdocstrings.css" rel="stylesheet"/><link href="../../assets/stylesheets/extra.css" rel="stylesheet"/><link href="../../assets/stylesheets/cards.css" rel="stylesheet"/><link href="../../assets/termynal/termynal.css" rel="stylesheet"/><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="default" dir="ltr"> <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script> <input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/> <input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/> <label class="md-overlay" for="__drawer"></label> <div data-md-component="skip"> <a class="md-skip" href="#training-api"> Skip to content </a> </div> <div data-md-component="announce"> <aside class="md-banner"> <div class="md-banner__inner md-grid md-typeset"> <button aria-label="Don't show this again" class="md-banner__button md-icon"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg> </button> Check out the new <a href=".">Model Training tutorial</a> ! </div> <script>var content,el=document.querySelector("[data-md-component=announce]");el&&(content=el.querySelector(".md-typeset"),__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0))</script> </aside> </div> <div data-md-color-scheme="default" data-md-component="outdated" hidden=""> </div> <header class="md-header md-header--shadow" data-md-component="header"> <nav aria-label="Header" class="md-header__inner md-grid"> <a aria-label="EDS-NLP" class="md-header__button md-logo" data-md-component="logo" href="../.." title="EDS-NLP"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg> </a> <label class="md-header__button md-icon" for="__drawer"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg> </label> <div class="md-header__title" data-md-component="header-title"> <div class="md-header__ellipsis"> <div class="md-header__topic"> <span class="md-ellipsis"> EDS-NLP </span> </div> <div class="md-header__topic" data-md-component="header-topic"> <span class="md-ellipsis"> Training API </span> </div> </div> </div> <form class="md-header__option" data-md-component="palette"> <input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_1" name="__palette" type="radio"/> <label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to dark mode"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg> </label> <input aria-label="Switch to light mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="" data-md-color-primary="indigo" data-md-color-scheme="slate" id="__palette_2" name="__palette" type="radio"/> <label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg> </label> </form> <label class="md-header__button md-icon" for="__search"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg> </label> <div class="md-search" data-md-component="search" role="dialog"> <label class="md-search__overlay" for="__search"></label> <div class="md-search__inner" role="search"> <form class="md-search__form" name="search"> <input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/> <label class="md-search__icon md-icon" for="__search"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg> </label> <nav aria-label="Search" class="md-search__options"> <button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" title="Clear" type="reset"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg> </button> </nav> </form> <div class="md-search__output"> <div class="md-search__scrollwrap" data-md-scrollfix=""> <div class="md-search-result" data-md-component="search-result"> <div class="md-search-result__meta"> Initializing search </div> <ol class="md-search-result__list" role="presentation"></ol> </div> </div> </div> </div> </div> <div class="md-header__source"> <a class="md-source" data-md-component="source" href="https://github.com/aphp/edsnlp" title="Go to repository"> <div class="md-source__icon md-icon"> <svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!-- Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg> </div> <div class="md-source__repository"> aphp/edsnlp </div> </a> </div> </nav> </header> <div class="md-container" data-md-component="container"> <main class="md-main" data-md-component="main"> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation"> <div class="md-sidebar__scrollwrap"> <div class="md-sidebar__inner"> <nav aria-label="Navigation" class="md-nav md-nav--primary" data-md-level="0"> <label class="md-nav__title" for="__drawer"> <a aria-label="EDS-NLP" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="EDS-NLP"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg> </a> EDS-NLP </label> <div class="md-nav__source"> <a class="md-source" data-md-component="source" href="https://github.com/aphp/edsnlp" title="Go to repository"> <div class="md-source__icon md-icon"> <svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!-- Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg> </div> <div class="md-source__repository"> aphp/edsnlp </div> </a> </div> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../.."> <span class="md-ellipsis"> Getting started </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="https://aphp.github.io/edsnlp/demo" target="_blank"> <span class="md-ellipsis"> Demo </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input checked="" class="md-nav__toggle md-toggle" id="__nav_3" type="checkbox"/> <div class="md-nav__link md-nav__container"> <a class="md-nav__link" href="../"> <span class="md-ellipsis"> Tutorials </span> </a> <label class="md-nav__link" for="__nav_3"> <span class="md-nav__icon md-icon"></span> </label> </div> <nav aria-expanded="true" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1"> <label class="md-nav__title" for="__nav_3"> <span class="md-nav__icon md-icon"></span> Tutorials </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../"> <span class="md-ellipsis"> Overview </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../spacy101/"> <span class="md-ellipsis"> SpaCy representations </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../matching-a-terminology/"> <span class="md-ellipsis"> Matching a terminology </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../qualifying-entities/"> <span class="md-ellipsis"> Qualifying entities </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../visualization/"> <span class="md-ellipsis"> Visualization </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../detecting-dates/"> <span class="md-ellipsis"> Detecting dates </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../reason/"> <span class="md-ellipsis"> Detecting Reason of Hospitalisation </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../endlines/"> <span class="md-ellipsis"> Detecting end-of-lines </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../aggregating-results/"> <span class="md-ellipsis"> Aggregating results </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../multiple-texts/"> <span class="md-ellipsis"> Processing multiple texts </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../advanced-tutorials/fastapi/"> <span class="md-ellipsis"> Deploying as an API </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../make-a-training-script/"> <span class="md-ellipsis"> Deep-learning tutorial </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/> <label class="md-nav__link md-nav__link--active" for="__toc"> <span class="md-ellipsis"> Training API </span> <span class="md-nav__icon md-icon"></span> </label> <a class="md-nav__link md-nav__link--active" href="./"> <span class="md-ellipsis"> Training API </span> </a> <nav aria-label="Table of contents" class="md-nav md-nav--secondary"> <label class="md-nav__title" for="__toc"> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="#creating-a-project"> Creating a project </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#training-the-model"> Training the model </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#use-the-model"> Use the model </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#packaging-the-model"> Packaging the model </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tuning/"> <span class="md-ellipsis"> Hyperparameter Tuning </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class="md-nav__link" href="../../pipes/"> <span class="md-ellipsis"> Pipes </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../tokenizers/"> <span class="md-ellipsis"> Tokenizers </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class="md-nav__link" href="../../data/"> <span class="md-ellipsis"> Data Connectors </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class="md-nav__link" href="../../concepts/pipeline/"> <span class="md-ellipsis"> Concepts </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class="md-nav__link" href="../../utilities/"> <span class="md-ellipsis"> Utilities </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class="md-nav__link" href="../../reference/edsnlp/"> <span class="md-ellipsis"> Code Reference </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../contributing/"> <span class="md-ellipsis"> Contributing to EDS-NLP </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../changelog/"> <span class="md-ellipsis"> Changelog </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc"> <div class="md-sidebar__scrollwrap"> <div class="md-sidebar__inner"> <nav aria-label="Table of contents" class="md-nav md-nav--secondary"> <label class="md-nav__title" for="__toc"> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="#creating-a-project"> Creating a project </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#training-the-model"> Training the model </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#use-the-model"> Use the model </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#packaging-the-model"> Packaging the model </a> </li> </ul> </nav> </div> </div> </div> <div class="md-content" data-md-component="content"> <article class="md-content__inner md-typeset"> <h1 id="training-api">Training API</h1> <p>In this tutorial, we'll see how we can quickly train a deep learning model with EDS-NLP using the <code>edsnlp.train</code> function.</p> <div class="admonition warning"> <p class="admonition-title">Hardware requirements</p> <p>Training a modern deep learning model requires a lot of computational resources. We recommend using a machine with a GPU, ideally with at least 16GB of VRAM. If you don't have access to a GPU, you can use a cloud service like <a href="https://colab.research.google.com/">Google Colab</a>, <a href="https://www.kaggle.com/">Kaggle</a>, <a href="https://www.paperspace.com/">Paperspace</a> or <a href="https://vast.ai/">Vast.ai</a>.</p> </div> <p>If you need a high level of control over the training procedure, we suggest you read the previous <a href="../make-a-training-script/">"Deep learning tutorial"</a> to understand how to build a training loop from scratch with EDS-NLP.</p> <h2 id="creating-a-project">Creating a project</h2> <p>If you already have installed <code>edsnlp[ml]</code> and do not want to setup a project, you can skip to the <a href="#training-the-model">next section</a>.</p> <p>Create a new project:</p> <div class="highlight" data-md-color-scheme="slate"><pre><span></span><code>mkdir<span class="w"> </span>my_ner_project
<span class="nb">cd</span><span class="w"> </span>my_ner_project

touch<span class="w"> </span>README.md<span class="w"> </span>pyproject.toml
mkdir<span class="w"> </span>-p<span class="w"> </span>configs<span class="w"> </span>data/dataset
</code></pre></div> <p>Add a standard <code>pyproject.toml</code> file with the following content. This file will be used to manage the dependencies of the project and its versioning.</p> <div class="highlight"><span class="filename">pyproject.toml</span><pre><span></span><code><span class="k">[project]</span>
<span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"my_ner_project"</span>
<span class="n">version</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"0.1.0"</span>
<span class="n">description</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">""</span>
<span class="n">authors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="n">name</span><span class="p">=</span><span class="s2">"Firstname Lastname"</span><span class="p">,</span><span class="w"> </span><span class="n">email</span><span class="p">=</span><span class="s2">"firstname.lastname@domain.com"</span><span class="w"> </span><span class="p">}</span>
<span class="p">]</span>
<span class="n">readme</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"README.md"</span>
<span class="n">requires-python</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"&gt;3.7.1,&lt;4.0"</span>

<span class="n">dependencies</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">"edsnlp[ml]&gt;=0.16.0"</span><span class="p">,</span>
<span class="w">    </span><span class="s2">"sentencepiece&gt;=0.1.96"</span>
<span class="p">]</span>

<span class="k">[project.optional-dependencies]</span>
<span class="n">dev</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">"dvc&gt;=2.37.0; python_version &gt;= '3.8'"</span><span class="p">,</span>
<span class="w">    </span><span class="s2">"pandas&gt;=1.1.0,&lt;2.0.0; python_version &lt; '3.8'"</span><span class="p">,</span>
<span class="w">    </span><span class="s2">"pandas&gt;=1.4.0,&lt;2.0.0; python_version &gt;= '3.8'"</span><span class="p">,</span>
<span class="w">    </span><span class="s2">"pre-commit&gt;=2.18.1"</span><span class="p">,</span>
<span class="w">    </span><span class="s2">"accelerate&gt;=0.21.0; python_version &gt;= '3.8'"</span><span class="p">,</span>
<span class="w">    </span><span class="s2">"rich-logger&gt;=0.3.0"</span>
<span class="p">]</span>
</code></pre></div> <p>We recommend using a virtual environment ("venv") to isolate the dependencies of your project and using <a href="https://docs.astral.sh/uv/">uv</a> to install the dependencies:</p> <div class="highlight" data-md-color-scheme="slate"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>uv
<span class="c1"># skip the next two lines if you do not want a venv</span>
uv<span class="w"> </span>venv<span class="w"> </span>.venv
<span class="nb">source</span><span class="w"> </span>.venv/bin/activate
uv<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span><span class="s2">".[dev]"</span><span class="w"> </span>-p<span class="w"> </span><span class="k">$(</span>uv<span class="w"> </span>python<span class="w"> </span>find<span class="k">)</span>
</code></pre></div> <h2 id="training-the-model">Training the model</h2> <p>EDS-NLP supports training models either <a href="#from-the-command-line">from the command line</a> or <a href="#from-a-script-or-a-notebook">from a Python script or notebook</a>, and switching between the two is straightforward thanks to the use of <a href="https://aphp.github.io/confit/">Confit</a>.</p> <details class="note"> <summary>A word about Confit</summary> <p>EDS-NLP makes heavy use of <a href="https://aphp.github.io/confit/">Confit</a>, a configuration library that allows you call functions from Python or the CLI, and validate and optionally cast their arguments.</p> <p>The EDS-NLP function used in this script is the <code>train</code> function of the <code>edsnlp.train</code> module. When passing a dict to a type-hinted argument (either from a <code>config.yml</code> file, or by calling the function in Python), Confit will instantiate the correct class with the arguments provided in the dict. For instance, we pass a dict to the <code>val_data</code> parameter, which is actually type hinted as a <code>SampleGenerator</code>: this dict will actually be used as keyword arguments to instantiate this <code>SampleGenerator</code> object. You can also instantiate a <code>SampleGenerator</code> object directly and pass it to the function.</p> <p>You can also tell Confit specifically which class you want to instantiate by using the <code>@register_name = "name_of_the_registered_class"</code> key and value in a dict or config section. We make a heavy use of this mechanism to build pipeline architectures.</p> </details> <div class="tabbed-set tabbed-alternate" data-tabs="1:2"><input checked="checked" id="from-the-command-line" name="__tabbed_1" type="radio"/><input id="from-a-script-or-a-notebook" name="__tabbed_1" type="radio"/><div class="tabbed-labels"><label for="from-the-command-line">From the command line</label><label for="from-a-script-or-a-notebook">From a script or a notebook</label></div> <div class="tabbed-content"> <div class="tabbed-block"> <p>Create a <code>config.yml</code> file in the <code>configs</code> folder with the following content:</p> <div class="highlight"><span class="filename">configs/config.yml</span><pre><span></span><code><span class="c1"># Some variables are grouped here for conviency but we could also</span>
<span class="c1"># put their values directly in the config in place of their reference</span>
<span class="nt">vars</span><span class="p">:</span>
<span class="w">  </span><span class="nt">train</span><span class="p">:</span><span class="w"> </span><span class="s">'./data/dataset/train'</span>
<span class="w">  </span><span class="nt">dev</span><span class="p">:</span><span class="w"> </span><span class="s">'./data/dataset/test'</span>

<span class="c1"># 🤖 PIPELINE DEFINITION</span>
<span class="nt">nlp</span><span class="p">:</span>
<span class="w">  </span><span class="s">'@core'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pipeline</span><span class="w">  </span><span class="c1">#(1)!</span>
<span class="w">  </span><span class="nt">lang</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">eds</span><span class="w">  </span><span class="c1"># Word-level tokenization: use the "eds" tokenizer</span>

<span class="w">  </span><span class="c1"># Our pipeline will contain a single NER pipe</span>
<span class="w">  </span><span class="c1"># The NER pipe will be a CRF model</span>
<span class="w">  </span><span class="nt">components</span><span class="p">:</span>
<span class="w">    </span><span class="nt">ner</span><span class="p">:</span>
<span class="w">      </span><span class="s">'@factory'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain"><a href="../../pipes/trainable/ner/#edsnlp.pipes.trainable.ner_crf.factory.create_component">eds.ner_crf</a></span>
<span class="w">      </span><span class="nt">mode</span><span class="p">:</span><span class="w"> </span><span class="s">'joint'</span>
<span class="w">      </span><span class="nt">target_span_getter</span><span class="p">:</span><span class="w"> </span><span class="s">'gold_spans'</span>
<span class="w">      </span><span class="c1"># Set spans as both to ents and in separate `ent.label` groups</span>
<span class="w">      </span><span class="nt">span_setter</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="w"> </span><span class="s">"ents"</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">"*"</span><span class="w"> </span><span class="p p-Indicator">]</span>
<span class="w">      </span><span class="nt">infer_span_setter</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>

<span class="w">      </span><span class="c1"># The CRF model will use a CNN to re-contextualize embeddings</span>
<span class="w">      </span><span class="nt">embedding</span><span class="p">:</span>
<span class="w">        </span><span class="s">'@factory'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain"><a href="../../pipes/trainable/embeddings/text_cnn/#edsnlp.pipes.trainable.embeddings.text_cnn.factory.create_component">eds.text_cnn</a></span>
<span class="w">        </span><span class="nt">kernel_sizes</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="w"> </span><span class="nv">3</span><span class="w"> </span><span class="p p-Indicator">]</span>

<span class="w">        </span><span class="c1"># The base embeddings will be computed by a transformer</span>
<span class="w">        </span><span class="nt">embedding</span><span class="p">:</span>
<span class="w">          </span><span class="s">'@factory'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain"><a href="../../pipes/trainable/embeddings/transformer/#edsnlp.pipes.trainable.embeddings.transformer.factory.create_component">eds.transformer</a></span>
<span class="w">          </span><span class="nt">model</span><span class="p">:</span><span class="w"> </span><span class="s">'camembert-base'</span>
<span class="w">          </span><span class="nt">window</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">128</span>
<span class="w">          </span><span class="nt">stride</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">96</span>

<span class="c1"># 📈 SCORERS</span>
<span class="nt">scorer</span><span class="p">:</span>
<span class="w">  </span><span class="nt">ner</span><span class="p">:</span>
<span class="w">    </span><span class="s">'@metrics'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">eds.ner_exact</span>
<span class="w">    </span><span class="nt">span_getter</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ nlp.components.ner.target_span_getter }</span>

<span class="c1"># 🎛️ OPTIMIZER</span>
<span class="nt">optimizer</span><span class="p">:</span>
<span class="w">  </span><span class="s">"@core"</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">optimizer</span>
<span class="w">  </span><span class="nt">optim</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">adamw</span>
<span class="w">  </span><span class="nt">groups</span><span class="p">:</span>
<span class="w">    </span><span class="c1"># Assign parameters starting with transformer (ie the parameters of the transformer component)</span>
<span class="w">    </span><span class="c1"># to a first group</span>
<span class="w">    </span><span class="s">"^transformer"</span><span class="p p-Indicator">:</span>
<span class="w">      </span><span class="nt">lr</span><span class="p">:</span>
<span class="w">        </span><span class="s">'@schedules'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">linear</span>
<span class="w">        </span><span class="s">"warmup_rate"</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">        </span><span class="s">"start_value"</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">        </span><span class="s">"max_value"</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5e-5</span>
<span class="w">    </span><span class="c1"># And every other parameters to the second group</span>
<span class="w">    </span><span class="s">""</span><span class="p p-Indicator">:</span>
<span class="w">      </span><span class="nt">lr</span><span class="p">:</span>
<span class="w">        </span><span class="s">'@schedules'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">linear</span>
<span class="w">        </span><span class="s">"warmup_rate"</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">        </span><span class="s">"start_value"</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3e-4</span>
<span class="w">        </span><span class="s">"max_value"</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3e-4</span>
<span class="w">  </span><span class="nt">module</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ nlp }</span>
<span class="w">  </span><span class="nt">total_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ train.max_steps }</span>

<span class="c1"># 📚 DATA</span>
<span class="nt">train_data</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">data</span><span class="p">:</span>
<span class="w">      </span><span class="c1"># In what kind of files (ie. their extensions) is our</span>
<span class="w">      </span><span class="c1"># training data stored</span>
<span class="w">      </span><span class="s">'@readers'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">standoff</span>
<span class="w">      </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ vars.train }</span>
<span class="w">      </span><span class="nt">converter</span><span class="p">:</span>
<span class="w">        </span><span class="c1"># What schema is used in the data files</span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">'@factory'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain"><a href="../../data/converters/#edsnlp.data.converters.StandoffDict2DocConverter">eds.standoff_dict2doc</a></span>
<span class="w">          </span><span class="nt">span_setter</span><span class="p">:</span><span class="w"> </span><span class="s">'gold_spans'</span>
<span class="w">        </span><span class="c1"># How to preprocess each doc for training</span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">'@factory'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain"><a href="../../pipes/misc/split/#edsnlp.pipes.misc.split.split.Split">eds.split</a></span>
<span class="w">          </span><span class="nt">nlp</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">          </span><span class="nt">max_length</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2000</span>
<span class="w">          </span><span class="nt">regex</span><span class="p">:</span><span class="w"> </span><span class="s">'\n\n+'</span>
<span class="w">    </span><span class="nt">shuffle</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dataset</span>
<span class="w">    </span><span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4096 tokens</span><span class="w">  </span><span class="c1"># 32 * 128 tokens</span>
<span class="w">    </span><span class="nt">pipe_names</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="w"> </span><span class="s">"ner"</span><span class="w"> </span><span class="p p-Indicator">]</span>

<span class="nt">val_data</span><span class="p">:</span>
<span class="w">  </span><span class="s">'@readers'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">standoff</span>
<span class="w">  </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ vars.dev }</span>
<span class="w">  </span><span class="c1"># What schema is used in the data files</span>
<span class="w">  </span><span class="nt">converter</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">'@factory'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain"><a href="../../data/converters/#edsnlp.data.converters.StandoffDict2DocConverter">eds.standoff_dict2doc</a></span>
<span class="w">      </span><span class="nt">span_setter</span><span class="p">:</span><span class="w"> </span><span class="s">'gold_spans'</span>

<span class="c1"># 🚀 TRAIN SCRIPT OPTIONS</span>
<span class="c1"># -&gt; python -m edsnlp.train --config configs/config.yml</span>
<span class="nt">train</span><span class="p">:</span>
<span class="w">  </span><span class="nt">nlp</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ nlp }</span>
<span class="w">  </span><span class="nt">output_dir</span><span class="p">:</span><span class="w"> </span><span class="s">'artifacts'</span>
<span class="w">  </span><span class="nt">train_data</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ train_data }</span>
<span class="w">  </span><span class="nt">val_data</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ val_data }</span>
<span class="w">  </span><span class="nt">max_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2000</span>
<span class="w">  </span><span class="nt">validation_interval</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ train.max_steps//10 }</span>
<span class="w">  </span><span class="nt">grad_max_norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0</span>
<span class="w">  </span><span class="nt">scorer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ scorer }</span>
<span class="w">  </span><span class="nt">optimizer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ optimizer }</span>
<span class="w">  </span><span class="c1"># Do preprocessing in parallel on 1 worker</span>
<span class="w">  </span><span class="nt">num_workers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">  </span><span class="c1"># Enable on Mac OS X or if you don't want to use available GPUs</span>
<span class="w">  </span><span class="c1"># cpu: true</span>

<span class="c1"># 📦 PACKAGE SCRIPT OPTIONS</span>
<span class="c1"># -&gt; python -m edsnlp.package --config configs/config.yml</span>
<span class="nt">package</span><span class="p">:</span>
<span class="w">  </span><span class="nt">pipeline</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ train.output_dir }</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s">'my_ner_model'</span>
</code></pre></div> <ol> <li> <p>Why do we use <code>'@core': pipeline</code> here ? Because we need the reference used in <code>optimizer.module = ${ nlp }</code> to be the actual Pipeline and not its keyword arguments : when confit sees <code>'@core': pipeline</code>, it will instantiate the <code>Pipeline</code> class with the arguments provided in the dict.</p> <p>In fact, you could also use <code>'@core': eds.pipeline</code> in every config when you define a pipeline, but sometimes it's more convenient to let Confit infer that the type of the nlp argument based on the function when it's type hinted. Not specifying <code>'@core': pipeline</code> is also more aligned with <code>spacy</code>'s pipeline config API. However, in general, explicit is better than implicit, so feel free to use explicitly write <code>'@core': eds.pipeline</code> when you define a pipeline.</p> </li> </ol> <p>To train the model, you can use the following command:</p> <div class="highlight" data-md-color-scheme="slate"><pre><span></span><code>python<span class="w"> </span>-m<span class="w"> </span>edsnlp.train<span class="w"> </span>--config<span class="w"> </span>configs/config.yml<span class="w"> </span>--seed<span class="w"> </span><span class="m">42</span>
</code></pre></div> <p><em>Any option can also be set either via the CLI or in <code>config.yml</code> under <code>[train]</code>.</em></p> </div> <div class="tabbed-block"> <p>Create a notebook, with the following content:</p> <div class="no-check highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">edsnlp</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">edsnlp.training</span><span class="w"> </span><span class="kn">import</span> <span class="n"><html><head></head><body><a class="discrete-link" href="../../reference/edsnlp/training/trainer/#edsnlp.training.trainer.train">train</a></body></html></span><span class="p">,</span> <span class="n"><html><head></head><body><a class="discrete-link" href="../../reference/edsnlp/training/optimizer/#edsnlp.training.optimizer.ScheduledOptimizer">ScheduledOptimizer</a></body></html></span><span class="p">,</span> <span class="n"><html><head></head><body><a class="discrete-link" href="../../reference/edsnlp/training/trainer/#edsnlp.training.trainer.TrainingData">TrainingData</a></body></html></span>
<span class="kn">from</span><span class="w"> </span><span class="nn">edsnlp.metrics.ner</span><span class="w"> </span><span class="kn">import</span> <span class="n">NerExactMetric</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">edsnlp.pipes</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">eds</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># 🤖 PIPELINE DEFINITION</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">edsnlp</span><span class="o">.</span><span class="n"><html><head></head><body><a class="discrete-link" href="../../reference/edsnlp/core/pipeline/#edsnlp.core.pipeline.blank">blank</a></body></html></span><span class="p">(</span><span class="s2">"eds"</span><span class="p">)</span>
<span class="n">nlp</span><span class="o">.</span><span class="n">add_pipe</span><span class="p">(</span>
    <span class="c1"># The NER pipe will be a CRF model</span>
    <a href="../../pipes/trainable/ner/#edsnlp.pipes.trainable.ner_crf.factory.create_component">eds.ner_crf</a><span class="p">(</span>
        <span class="n">mode</span><span class="o">=</span><span class="s2">"joint"</span><span class="p">,</span>
        <span class="n">target_span_getter</span><span class="o">=</span><span class="s2">"gold_spans"</span><span class="p">,</span>
        <span class="c1"># Set spans as both to ents and in separate `ent.label` groups</span>
        <span class="n">span_setter</span><span class="o">=</span><span class="p">[</span><span class="s2">"ents"</span><span class="p">,</span> <span class="s2">"*"</span><span class="p">],</span>
        <span class="n">infer_span_setter</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="c1"># The CRF model will use a CNN to re-contextualize embeddings</span>
        <span class="n">embedding</span><span class="o">=</span><a href="../../pipes/trainable/embeddings/text_cnn/#edsnlp.pipes.trainable.embeddings.text_cnn.factory.create_component">eds.text_cnn</a><span class="p">(</span>
            <span class="n">kernel_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
            <span class="c1"># The base embeddings will be computed by a transformer</span>
            <span class="n">embedding</span><span class="o">=</span><a href="../../pipes/trainable/embeddings/transformer/#edsnlp.pipes.trainable.embeddings.transformer.factory.create_component">eds.transformer</a><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="s2">"camembert-base"</span><span class="p">,</span>
                <span class="n">window</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                <span class="n">stride</span><span class="o">=</span><span class="mi">96</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1"># 📈 SCORERS</span>
<span class="n">ner_metric</span> <span class="o">=</span> <span class="n">NerExactMetric</span><span class="p">(</span><span class="n">span_getter</span><span class="o">=</span><span class="s2">"gold_spans"</span><span class="p">)</span>

<span class="c1"># 📚 DATA</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">edsnlp</span><span class="o">.</span><span class="n">data</span>
    <span class="o">.</span><span class="n"><html><head></head><body><a class="discrete-link" href="../../data/standoff/#edsnlp.data.standoff.read_standoff">read_standoff</a></body></html></span><span class="p">(</span><span class="s2">"./data/dataset/train"</span><span class="p">,</span> <span class="n">span_setter</span><span class="o">=</span><span class="s2">"gold_spans"</span><span class="p">)</span>
    <span class="o">.</span><span class="n">map</span><span class="p">(</span><a href="../../pipes/misc/split/#edsnlp.pipes.misc.split.split.Split">eds.split</a><span class="p">(</span><span class="n">nlp</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">regex</span><span class="o">=</span><span class="s2">"</span><span class="se">\n\n</span><span class="s2">+"</span><span class="p">))</span>
<span class="p">)</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">edsnlp</span><span class="o">.</span><span class="n">data</span>
    <span class="o">.</span><span class="n"><html><head></head><body><a class="discrete-link" href="../../data/standoff/#edsnlp.data.standoff.read_standoff">read_standoff</a></body></html></span><span class="p">(</span><span class="s2">"./data/dataset/test"</span><span class="p">,</span> <span class="n">span_setter</span><span class="o">=</span><span class="s2">"gold_spans"</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># 🎛️ OPTIMIZER</span>
<span class="n">max_steps</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n"><html><head></head><body><a class="discrete-link" href="../../reference/edsnlp/training/optimizer/#edsnlp.training.optimizer.ScheduledOptimizer">ScheduledOptimizer</a></body></html></span><span class="p">(</span>
    <span class="n">optim</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span>
    <span class="n">module</span><span class="o">=</span><span class="n">nlp</span><span class="p">,</span>
    <span class="n">total_steps</span><span class="o">=</span><span class="n">max_steps</span><span class="p">,</span>
    <span class="n">groups</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">"^transformer"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">"lr"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"@schedules"</span><span class="p">:</span> <span class="s2">"linear"</span><span class="p">,</span> <span class="s2">"warmup_rate"</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span> <span class="s2">"start_value"</span><span class="p">:</span> <span class="mi">0</span> <span class="s2">"max_value"</span><span class="p">:</span> <span class="mf">5e-5</span><span class="p">,},</span>
        <span class="p">},</span>
        <span class="s2">""</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">"lr"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"@schedules"</span><span class="p">:</span> <span class="s2">"linear"</span><span class="p">,</span> <span class="s2">"warmup_rate"</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span> <span class="s2">"start_value"</span><span class="p">:</span> <span class="mf">3e-4</span> <span class="s2">"max_value"</span><span class="p">:</span> <span class="mf">3e-4</span><span class="p">,},</span>
        <span class="p">},</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="c1"># 🚀 TRAIN</span>
<span class="n"><html><head></head><body><a class="discrete-link" href="../../reference/edsnlp/training/trainer/#edsnlp.training.trainer.train">train</a></body></html></span><span class="p">(</span>
    <span class="n">nlp</span><span class="o">=</span><span class="n">nlp</span><span class="p">,</span>
    <span class="n">max_steps</span><span class="o">=</span><span class="n">max_steps</span><span class="p">,</span>
    <span class="n">validation_interval</span><span class="o">=</span><span class="n">max_steps</span> <span class="o">//</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">train_data</span><span class="o">=</span><span class="n"><html><head></head><body><a class="discrete-link" href="../../reference/edsnlp/training/trainer/#edsnlp.training.trainer.TrainingData">TrainingData</a></body></html></span><span class="p">(</span>
        <span class="n">data</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="s2">"4096 tokens"</span><span class="p">,</span>  <span class="c1"># 32 * 128 tokens</span>
        <span class="n">pipe_names</span><span class="o">=</span><span class="p">[</span><span class="s2">"ner"</span><span class="p">],</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="s2">"dataset"</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">val_data</span><span class="o">=</span><span class="n">val_data</span><span class="p">,</span>
    <span class="n">scorer</span><span class="o">=</span><span class="p">{</span><span class="s2">"ner"</span><span class="p">:</span> <span class="n">ner_metric</span><span class="p">},</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">grad_max_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="s2">"artifacts"</span><span class="p">,</span>
    <span class="c1"># Do preprocessing in parallel on 1 worker</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="c1"># Enable on Mac OS X or if you don't want to use available GPUs</span>
    <span class="c1"># cpu=True,</span>
<span class="p">)</span>
</code></pre></div> </div> </div> </div> <p>or use the config file:</p> <div class="no-check highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">edsnlp.train</span><span class="w"> </span><span class="kn">import</span> <span class="n"><html><head></head><body><a class="discrete-link" href="../../reference/edsnlp/training/trainer/#edsnlp.training.trainer.train">train</a></body></html></span>
<span class="kn">import</span><span class="w"> </span><span class="nn">edsnlp</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">confit</span>

<span class="n">cfg</span> <span class="o">=</span> <span class="n">confit</span><span class="o">.</span><span class="n">Config</span><span class="o">.</span><span class="n">from_disk</span><span class="p">(</span>
    <span class="s2">"configs/config.yml"</span><span class="p">,</span> <span class="n">resolve</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">registry</span><span class="o">=</span><span class="n">edsnlp</span><span class="o">.</span><span class="n">registry</span>
<span class="p">)</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n"><html><head></head><body><a class="discrete-link" href="../../reference/edsnlp/training/trainer/#edsnlp.training.trainer.train">train</a></body></html></span><span class="p">(</span><span class="o">**</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"train"</span><span class="p">])</span>
</code></pre></div> <p>Here are the parameters you can pass to the <code>train</code> function:</p> <div class="doc doc-object doc-function"> <div class="doc doc-contents first"> <h4 id="edsnlp.training.trainer.train--parameters">Parameters</h4> <table> <thead> <tr> <th><b>PARAMETER</b></th> <th><b>DESCRIPTION</b></th> </tr> </thead> <tbody> <tr> <td><code>nlp</code></td> <td class="doc-param-details"> <p>The pipeline that will be trained in place.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><a class="autorefs autorefs-internal" href="../../concepts/pipeline/#edsnlp.core.pipeline.Pipeline" title="edsnlp.Pipeline">Pipeline</a></code> </span> </p> </td> </tr> <tr> <td><code>train_data</code></td> <td class="doc-param-details"> <p>The training data. Can be a single <a class="autorefs autorefs-internal" href="../../reference/edsnlp/training/trainer/#edsnlp.training.trainer.TrainingData">TrainingData</a> object, a dict that will be cast or a list of these objects.</p> <details class="note"> <summary><code>TrainingData</code> object/dictionary</summary> <div class="doc doc-object doc-class"> <table> <thead> <tr> <th><b>PARAMETER</b></th> <th><b>DESCRIPTION</b></th> </tr> </thead> <tbody> <tr> <td><code>data</code></td> <td class="doc-param-details"> <p>The stream of documents to train on. The documents will be preprocessed and collated according to the pipeline's components.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><a class="autorefs autorefs-internal" href="../../concepts/inference/#edsnlp.core.stream.Stream" title="edsnlp.core.stream.Stream">Stream</a></code> </span> </p> </td> </tr> <tr> <td><code>batch_size</code></td> <td class="doc-param-details"> <p>The batch size. Can be a batching expression like "2000 words", an int (number of documents), or a tuple (batch_size, batch_by). The batch_by argument should be a statistic produced by the pipes that will be trained. For instance, the <code><a href="../../pipes/trainable/embeddings/span_pooler/#edsnlp.pipes.trainable.embeddings.span_pooler.factory.create_component">eds.span_pooler</a></code> component produces a "spans" statistic, that can be used to produce batches of no more than 16 spans by setting batch_size to "16 spans".</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><a class="autorefs autorefs-internal" href="../../reference/edsnlp/utils/batching/#edsnlp.utils.batching.BatchSizeArg" title="edsnlp.utils.batching.BatchSizeArg">BatchSizeArg</a></code> </span> </p> </td> </tr> <tr> <td><code>shuffle</code></td> <td class="doc-param-details"> <p>The shuffle strategy. Can be "dataset" to shuffle the entire dataset (this can be memory-intensive for large file based datasets), "fragment" to shuffle the fragment-based datasets like parquet files, or a batching expression like "2000 words" to shuffle the dataset in chunks of 2000 words.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Union">Union</span>[str, <span title="typing_extensions.Literal">Literal</span>[False]]</code> </span> </p> </td> </tr> <tr> <td><code>sub_batch_size</code></td> <td class="doc-param-details"> <p>How to split each batch into sub-batches that will be fed to the model independently to accumulate gradients over.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" href="../../reference/edsnlp/utils/batching/#edsnlp.utils.batching.BatchSizeArg" title="edsnlp.utils.batching.BatchSizeArg">BatchSizeArg</a>]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> <tr> <td><code>pipe_names</code></td> <td class="doc-param-details"> <p>The names of the pipes that should be trained on this data. If None, defaults to all trainable pipes.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Optional">Optional</span>[<span title="typing.Collection">Collection</span>[str]]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> <tr> <td><code>post_init</code></td> <td class="doc-param-details"> <p>Whether to call the pipeline's post_init method with the data before training.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code>bool</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>True</code> </span> </p> </td> </tr> </tbody> </table> </div></details> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="edsnlp.utils.typing.AsList">AsList</span>[<a class="autorefs autorefs-internal" href="../../reference/edsnlp/training/trainer/#edsnlp.training.trainer.TrainingData" title="edsnlp.training.trainer.TrainingData">TrainingData</a>]</code> </span> </p> </td> </tr> <tr> <td><code>val_data</code></td> <td class="doc-param-details"> <p>The validation data. Can be a single Stream object or a list of Stream.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="edsnlp.utils.typing.AsList">AsList</span>[<a class="autorefs autorefs-internal" href="../../concepts/inference/#edsnlp.core.stream.Stream" title="edsnlp.core.stream.Stream">Stream</a>]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>[]</code> </span> </p> </td> </tr> <tr> <td><code>seed</code></td> <td class="doc-param-details"> <p>The random seed</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code>int</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>42</code> </span> </p> </td> </tr> <tr> <td><code>max_steps</code></td> <td class="doc-param-details"> <p>The maximum number of training steps</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code>int</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>1000</code> </span> </p> </td> </tr> <tr> <td><code>optimizer</code></td> <td class="doc-param-details"> <p>The optimizer. If None, a default optimizer will be used.</p> <details class="note"> <summary><code>ScheduledOptimizer</code> object/dictionary</summary> <div class="doc doc-object doc-class"> <table> <thead> <tr> <th><b>PARAMETER</b></th> <th><b>DESCRIPTION</b></th> </tr> </thead> <tbody> <tr> <td><code>optim</code></td> <td class="doc-param-details"> <p>The optimizer to use. If a string (like "adamw") or a type to instantiate, the<code>module</code> and <code>groups</code> must be provided.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Union">Union</span>[str, <span title="typing.Type">Type</span>[<span title="torch.optim.Optimizer">Optimizer</span>], <span title="torch.optim.Optimizer">Optimizer</span>]</code> </span> </p> </td> </tr> <tr> <td><code>module</code></td> <td class="doc-param-details"> <p>The module to optimize. Usually the <code>nlp</code> pipeline object.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[<span title="edsnlp.core.PipelineProtocol">PipelineProtocol</span>, <span title="torch.nn.Module">Module</span>]]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> <tr> <td><code>total_steps</code></td> <td class="doc-param-details"> <p>The total number of steps, used for schedules.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Optional">Optional</span>[int]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> <tr> <td><code>groups</code></td> <td class="doc-param-details"> <p>The groups to optimize. The key is a regex selector to match parameters in <code>module.named_parameters()</code> and the value is a dictionary with the keys <code>params</code> and <code>schedules</code>.</p> <p>The matching is performed by running <code>regex.search(selector, name)</code> so you do not have to match the full name. Note that the order of dict keys matter. If a parameter name matches multiple selectors, the configurations of these selectors are combined in reverse order (from the last matched selector to the first), allowing later selectors to complete options from earlier ones. If a selector maps to <code>False</code>, any parameters matching it are excluded from optimization and not included in any parameter group.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Optional">Optional</span>[<span title="typing.Dict">Dict</span>[str, Group]]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> </tbody> </table> </div></details> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Union">Union</span>[<a class="autorefs autorefs-internal" href="../../reference/edsnlp/training/optimizer/#edsnlp.training.optimizer.ScheduledOptimizer" title="edsnlp.training.optimizer.ScheduledOptimizer">ScheduledOptimizer</a>, <span title="torch.optim.Optimizer">Optimizer</span>]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> <tr> <td><code>validation_interval</code></td> <td class="doc-param-details"> <p>The number of steps between each evaluation. Defaults to 1/10 of max_steps</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Optional">Optional</span>[int]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> <tr> <td><code>checkpoint_interval</code></td> <td class="doc-param-details"> <p>The number of steps between each model save. Defaults to validation_interval</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Optional">Optional</span>[int]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> <tr> <td><code>grad_max_norm</code></td> <td class="doc-param-details"> <p>The maximum gradient norm</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code>float</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>5.0</code> </span> </p> </td> </tr> <tr> <td><code>grad_dev_policy</code></td> <td class="doc-param-details"> <p>The policy to apply when a gradient spike is detected, ie. when the gradient norm is higher than the mean + std * grad_max_dev. Can be:</p> <ul> <li>"clip_mean": clip the gradients to the mean gradient norm</li> <li>"clip_threshold": clip the gradients to the mean + std * grad_max_dev</li> <li>"skip": skip the step</li> </ul> <p>These do not apply to <code>grad_max_norm</code> that is always enforced when it is not None, since <code>grad_max_norm</code> is not adaptive and would most likely prohibit the model from learning during the early stages of training when gradients are expected to be high.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Optional">Optional</span>[<span title="typing_extensions.Literal">Literal</span>['clip_mean', 'clip_threshold', 'skip']]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> <tr> <td><code>grad_ewm_window</code></td> <td class="doc-param-details"> <p>Approximately how many steps should we look back to compute the average gradient norm and variance to detect gradient deviation spikes.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code>int</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>100</code> </span> </p> </td> </tr> <tr> <td><code>grad_max_dev</code></td> <td class="doc-param-details"> <p>The threshold to apply to detect gradient spikes. A spike is detected when the value is higher than the mean + variance * threshold.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code>float</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>7.0</code> </span> </p> </td> </tr> <tr> <td><code>loss_scales</code></td> <td class="doc-param-details"> <p>The loss scales for each component (useful for multi-task learning)</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Dict">Dict</span>[str, float]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>{}</code> </span> </p> </td> </tr> <tr> <td><code>scorer</code></td> <td class="doc-param-details"> <p>How to score the model. Expects a <code>GenericScorer</code> object or a dict containing a mapping of metric names to metric objects.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="edsnlp.training.trainer.GenericScorer">GenericScorer</span></code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code><span title="edsnlp.training.trainer.GenericScorer">GenericScorer</span>()</code> </span> </p> </td> </tr> <tr> <td><code>num_workers</code></td> <td class="doc-param-details"> <p>The number of workers to use for preprocessing the data in parallel. Setting it to 0 means no parallelization : data is processed on the main thread which may induce latency slow down the training. To avoid this, a good practice consist in doing the preprocessing either before training or in parallel in a separate process. Because of how EDS-NLP handles stream multiprocessing, changing this value will affect the order of the documents in the produces batches. A stream [1, 2, 3, 4, 5, 6] split in batches of size 3 will produce:</p> <ul> <li>[1, 2, 3] and [4, 5, 6] with 1 worker</li> <li>[1, 3, 5] and [2, 4, 6] with 2 workers</li> </ul> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code>int</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>0</code> </span> </p> </td> </tr> <tr> <td><code>cpu</code></td> <td class="doc-param-details"> <p>Whether to use force training on CPU. On MacOS, this might be necessary to get around some <code>mps</code> backend issues.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code>bool</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>False</code> </span> </p> </td> </tr> <tr> <td><code>mixed_precision</code></td> <td class="doc-param-details"> <p>The mixed precision mode. Can be "no", "fp16", "bf16" or "fp8".</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing_extensions.Literal">Literal</span>['no', 'fp16', 'bf16', 'fp8']</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>'no'</code> </span> </p> </td> </tr> <tr> <td><code>output_dir</code></td> <td class="doc-param-details"> <p>The output directory, which will contain a <code>model-last</code> directory with the last model, and a <code>train_metrics.json</code> file with the training metrics and stats.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Union">Union</span>[<span title="pathlib.Path">Path</span>, str]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code><span title="pathlib.Path">Path</span>('artifacts')</code> </span> </p> </td> </tr> <tr> <td><code>output_model_dir</code></td> <td class="doc-param-details"> <p>The directory where to save the model. If None, defaults to <code>output_dir / "model-last"</code>.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[<span title="pathlib.Path">Path</span>, str]]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> <tr> <td><code>save_model</code></td> <td class="doc-param-details"> <p>Whether to save the model or not. This can be useful if you are only interested in the metrics, but no the model, and want to avoid spending time dumping the model weights to the disk.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code>bool</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>True</code> </span> </p> </td> </tr> <tr> <td><code>logger</code></td> <td class="doc-param-details"> <p>Whether to log the validation metrics in a rich table.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code>bool</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>True</code> </span> </p> </td> </tr> <tr> <td><code>log_weight_grads</code></td> <td class="doc-param-details"> <p>Whether to log the weight gradients during training.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code>bool</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>False</code> </span> </p> </td> </tr> <tr> <td><code>on_validation_callback</code></td> <td class="doc-param-details"> <p>A callback function invoked during validation steps to handle custom logic.</p> <p> <span class="doc-param-annotation"> <b>TYPE:</b> <code><span title="typing.Optional">Optional</span>[<span title="typing.Callable">Callable</span>[[<span title="typing.Dict">Dict</span>], None]]</code> </span> <span class="doc-param-default"> <b>DEFAULT:</b> <code>None</code> </span> </p> </td> </tr> <tr> <td><code>kwargs</code></td> <td class="doc-param-details"> <p>Additional keyword arguments.</p> <p> <span class="doc-param-default"> <b>DEFAULT:</b> <code>{}</code> </span> </p> </td> </tr> </tbody> </table> </div> </div><h2 id="use-the-model">Use the model</h2> <p>You can now load the model and use it to process some text:</p> <div class="no-check highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">edsnlp</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">edsnlp</span><span class="o">.</span><span class="n"><html><head></head><body><a class="discrete-link" href="../../reference/edsnlp/core/pipeline/#edsnlp.core.pipeline.load">load</a></body></html></span><span class="p">(</span><span class="s2">"artifacts/model-last"</span><span class="p">)</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="s2">"Some sample text"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">ent</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">label_</span><span class="p">)</span>
</code></pre></div> <h2 id="packaging-the-model">Packaging the model</h2> <p>To package the model and share it with friends or family (if the model does not contain sensitive data), you can use the following command:</p> <div class="highlight" data-md-color-scheme="slate"><pre><span></span><code>python<span class="w"> </span>-m<span class="w"> </span>edsnlp.package<span class="w"> </span>--pipeline<span class="w"> </span>artifacts/model-last/<span class="w"> </span>--name<span class="w"> </span>my_ner_model<span class="w"> </span>--distributions<span class="w"> </span>sdist
</code></pre></div> <p><em>Parametrize either via the CLI or in <code>config.yml</code> under <code>[package]</code>.</em></p> <p>Tthe model saved at the train script output path (<code>artifacts/model-last</code>) will be named <code>my_ner_model</code> and will be saved in the <code>dist</code> folder. You can upload it to a package registry or install it directly with</p> <div class="highlight" data-md-color-scheme="slate"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>dist/my_ner_model-0.1.0.tar.gz
</code></pre></div> <div class="footnote"><hr/><ol></ol></div> <script async="" crossorigin="anonymous" data-category="Announcements" data-category-id="DIC_kwDOG97JnM4CkS1h" data-emit-metadata="0" data-input-position="bottom" data-lang="en" data-mapping="title" data-reactions-enabled="1" data-repo="aphp/edsnlp" data-repo-id="R_kgDOG97JnA" data-strict="0" data-theme="https://aphp.github.io/edsnlp/master/assets/stylesheets/giscus_light.css" loading="lazy" src="https://giscus.app/client.js">
</script> <script>
    var giscus = document.querySelector("script[src*=giscus]")

    // Set palette on initial load
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
        var theme = palette.color.scheme === "slate"
            ? "https://aphp.github.io/edsnlp/master/assets/stylesheets/giscus_dark.css"
            : "https://aphp.github.io/edsnlp/master/assets/stylesheets/giscus_light.css"

        // Instruct Giscus to set theme
        giscus.setAttribute("data-theme", theme)
    }

    // Register event handlers after documented loaded
    document.addEventListener("DOMContentLoaded", function () {
        var ref = document.querySelector("[data-md-component=palette]")
        ref.addEventListener("change", function () {
            var palette = __md_get("__palette")
            if (palette && typeof palette.color === "object") {
                var theme = palette.color.scheme === "slate"
                    ? "https://aphp.github.io/edsnlp/master/assets/stylesheets/giscus_dark.css"
                    : "https://aphp.github.io/edsnlp/master/assets/stylesheets/giscus_light.css"

                // Instruct Giscus to change theme
                var frame = document.querySelector(".giscus-frame")
                frame.contentWindow.postMessage(
                    {giscus: {setConfig: {theme}}},
                    "https://giscus.app"
                )
            }
        })
    })
</script> </article> </div> </div> <button class="md-top md-icon" data-md-component="top" hidden="" type="button"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"></path></svg> Back to top </button> </main> <footer class="md-footer"> <nav aria-label="Footer" class="md-footer__inner md-grid"> <a aria-label="Previous: Deep-learning tutorial" class="md-footer__link md-footer__link--prev" href="../make-a-training-script/" rel="prev"> <div class="md-footer__button md-icon"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg> </div> <div class="md-footer__title"> <span class="md-footer__direction"> Previous </span> <div class="md-ellipsis"> Deep-learning tutorial </div> </div> </a> <a aria-label="Next: Hyperparameter Tuning" class="md-footer__link md-footer__link--next" href="../tuning/" rel="next"> <div class="md-footer__title"> <span class="md-footer__direction"> Next </span> <div class="md-ellipsis"> Hyperparameter Tuning </div> </div> <div class="md-footer__button md-icon"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"></path></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class="md-copyright"> Made with <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank"> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class="md-dialog" data-md-component="dialog"> <div class="md-dialog__inner md-typeset"></div> </div> <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tracking", "navigation.instant", "navigation.indexes", "navigation.prune", "navigation.top", "navigation.footer", "content.code.annotate", "content.code.copy", "announce.dismiss"], "search": "../../assets/javascripts/workers/search.dfff1995.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "latest", "provider": "mike"}}</script> <script src="../../assets/javascripts/bundle.dff1b7c8.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/vega@5"></script> <script src="https://cdn.jsdelivr.net/npm/vega-lite@5"></script> <script src="https://cdn.jsdelivr.net/npm/vega-embed@6"></script> <script src="../../assets/termynal/termynal.js"></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> </body> </html>