[nlp]
lang = "eds"
pipeline = [
    "normalizer",
    "sentencizer",
    "covid",
    "qualifier",
    ]
batch_size = 2
components = ${components}
tokenizer = {"@tokenizers": "eds.tokenizer"}

[components.normalizer]
@factory = "eds.normalizer"

[components.sentencizer]
@factory = "eds.sentences"

[components.covid]
@factory = "eds.covid"

# Qualifier component is:
# - a span qualifier, that classifies spans embedded by...
# - a span pooler, that pools words embedded by...
# - a text cnn, that re-contextualizes words embedded by...
# - a transformer
[components.qualifier]
@factory = "eds.span_classifier"
qualifiers = { "_.negation": [ "sosy" ] }
# needs to use interpolation since we use a star expression, which is python
span_getter = ${["ents", *vars.ml_span_groups]}
context_getter = { "@misc": "eds.span_context_getter" }

[components.qualifier.embedding]
@factory = "eds.span_pooler"

[components.qualifier.embedding.embedding]
@factory = "eds.text_cnn"
kernel_sizes = [3]

[components.qualifier.embedding.embedding.embedding]
@factory = "eds.transformer"
model = "hf-internal-testing/tiny-bert"
window = 128
stride = 96

[scorer.qual]
@metrics = "eds.span_attributes"
span_getter = ${vars.ml_span_groups}
qualifiers = ${components.qualifier.qualifiers}

[vars]
train = "dataset/dataset.jsonl"
dev = "dataset/dataset.jsonl"
ml_span_groups = ["sosy"]

[train]
nlp = ${nlp}
max_steps = 50
validation_interval = ${train.max_steps//10}
warmup_rate = 0
batch_size = 4 spans
transformer_lr = 0
task_lr = 1e-3
scorer = ${scorer}

[train.train_data]
randomize = true
max_length = 10
multi_sentence = false
[train.train_data.reader]
@readers: "json"
path: ${vars.train}
converter: "custom"
span_setter: ${vars.ml_span_groups}
span_attributes: "negation"
bool_attributes: ["negation"]

[train.val_data]
[train.val_data.reader]
@readers: "json"
path: ${vars.dev}
converter: "custom"
span_setter: ${vars.ml_span_groups}
span_attributes: "negation"
bool_attributes: ["negation"]
