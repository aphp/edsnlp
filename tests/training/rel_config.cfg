[nlp]
lang = "eds"
pipeline = [
    "normalizer",
    "sentencizer",
    "covid",
    "dates",
    "relations",
    ]
batch_size = 2
components = ${components}
tokenizer = {"@tokenizers": "eds.tokenizer"}

[components.normalizer]
@factory = "eds.normalizer"

[components.sentencizer]
@factory = "eds.sentences"

[components.covid]
@factory = "eds.covid"

[components.dates]
@factory = "eds.dates"

# Relations component is:
# - a span relation detector, that classifies pairs spans embedded by...
# - a span pooler, that pools words embedded by...
# - a text cnn, that re-contextualizes words embedded by...
# - a transformer
[components.relations]
@factory = "eds.relation_detector_ffn"
head_getter = {"ents": "covid"}
tail_getter = {"ents": "date"}
labels = ["linked"]
symmetric = true

[components.relations.word_embedding]
@factory = "eds.text_cnn"
kernel_sizes = [3]

[components.relations.word_embedding.embedding]
@factory = "eds.transformer"
model = "hf-internal-testing/tiny-bert"
window = 128
stride = 96

[components.relations.span_embedding]
@factory = "eds.span_pooler"
embedding = ${components.relations.word_embedding}

[scorer.rel]
@metrics = "eds.relations"
head_getter = ${components.relations.head_getter}
tail_getter = ${components.relations.tail_getter}
labels = ${components.relations.labels}

[train]
nlp = ${nlp}
max_steps = 50
validation_interval = ${train.max_steps//10}
warmup_rate = 0
batch_size = 2 samples
transformer_lr = 0
task_lr = 1e-3
scorer = ${scorer}

[train.train_data]
randomize = true
max_length = 100
multi_sentence = true
[train.train_data.reader]
@readers = "standoff"
path = "./dataset_2/"

[train.val_data]
[train.val_data.reader]
@readers = "standoff"
path = "./dataset_2/"
