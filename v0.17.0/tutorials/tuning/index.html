<!DOCTYPE html>
<html class="no-js" lang="en"> <head><meta charset="utf-8"/><meta content="width=device-width,initial-scale=1" name="viewport"/><link href="../training/" rel="prev"/><link href="../../pipes/" rel="next"/><link href="../../assets/logo/edsnlp.svg" rel="icon"/><meta content="mkdocs-1.5.3, mkdocs-material-9.2.8" name="generator"/><title>Hyperparameter Tuning - EDS-NLP</title><link href="../../assets/stylesheets/main.046329b4.min.css" rel="stylesheet"/><link href="../../assets/stylesheets/palette.85d0ee34.min.css" rel="stylesheet"/><link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/><link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link href="../../assets/_mkdocstrings.css" rel="stylesheet"/><link href="../../assets/stylesheets/extra.css" rel="stylesheet"/><link href="../../assets/stylesheets/cards.css" rel="stylesheet"/><link href="../../assets/termynal/termynal.css" rel="stylesheet"/><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="default" dir="ltr"> <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script> <input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/> <input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/> <label class="md-overlay" for="__drawer"></label> <div data-md-component="skip"> <a class="md-skip" href="#hyperparameter-tuning"> Skip to content </a> </div> <div data-md-component="announce"> <aside class="md-banner"> <div class="md-banner__inner md-grid md-typeset"> <button aria-label="Don't show this again" class="md-banner__button md-icon"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg> </button> Check out the new <a href="../training">Model Training tutorial</a> ! </div> <script>var content,el=document.querySelector("[data-md-component=announce]");el&&(content=el.querySelector(".md-typeset"),__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0))</script> </aside> </div> <div data-md-color-scheme="default" data-md-component="outdated" hidden=""> </div> <header class="md-header md-header--shadow" data-md-component="header"> <nav aria-label="Header" class="md-header__inner md-grid"> <a aria-label="EDS-NLP" class="md-header__button md-logo" data-md-component="logo" href="../.." title="EDS-NLP"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg> </a> <label class="md-header__button md-icon" for="__drawer"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg> </label> <div class="md-header__title" data-md-component="header-title"> <div class="md-header__ellipsis"> <div class="md-header__topic"> <span class="md-ellipsis"> EDS-NLP </span> </div> <div class="md-header__topic" data-md-component="header-topic"> <span class="md-ellipsis"> Hyperparameter Tuning </span> </div> </div> </div> <form class="md-header__option" data-md-component="palette"> <input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_1" name="__palette" type="radio"/> <label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to dark mode"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg> </label> <input aria-label="Switch to light mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="" data-md-color-primary="indigo" data-md-color-scheme="slate" id="__palette_2" name="__palette" type="radio"/> <label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg> </label> </form> <label class="md-header__button md-icon" for="__search"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg> </label> <div class="md-search" data-md-component="search" role="dialog"> <label class="md-search__overlay" for="__search"></label> <div class="md-search__inner" role="search"> <form class="md-search__form" name="search"> <input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/> <label class="md-search__icon md-icon" for="__search"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg> </label> <nav aria-label="Search" class="md-search__options"> <button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" title="Clear" type="reset"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg> </button> </nav> </form> <div class="md-search__output"> <div class="md-search__scrollwrap" data-md-scrollfix=""> <div class="md-search-result" data-md-component="search-result"> <div class="md-search-result__meta"> Initializing search </div> <ol class="md-search-result__list" role="presentation"></ol> </div> </div> </div> </div> </div> <div class="md-header__source"> <a class="md-source" data-md-component="source" href="https://github.com/aphp/edsnlp" title="Go to repository"> <div class="md-source__icon md-icon"> <svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!-- Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg> </div> <div class="md-source__repository"> aphp/edsnlp </div> </a> </div> </nav> </header> <div class="md-container" data-md-component="container"> <main class="md-main" data-md-component="main"> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation"> <div class="md-sidebar__scrollwrap"> <div class="md-sidebar__inner"> <nav aria-label="Navigation" class="md-nav md-nav--primary" data-md-level="0"> <label class="md-nav__title" for="__drawer"> <a aria-label="EDS-NLP" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="EDS-NLP"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg> </a> EDS-NLP </label> <div class="md-nav__source"> <a class="md-source" data-md-component="source" href="https://github.com/aphp/edsnlp" title="Go to repository"> <div class="md-source__icon md-icon"> <svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!-- Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg> </div> <div class="md-source__repository"> aphp/edsnlp </div> </a> </div> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../.."> <span class="md-ellipsis"> Getting started </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="https://aphp.github.io/edsnlp/demo" target="_blank"> <span class="md-ellipsis"> Demo </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input checked="" class="md-nav__toggle md-toggle" id="__nav_3" type="checkbox"/> <div class="md-nav__link md-nav__container"> <a class="md-nav__link" href="../"> <span class="md-ellipsis"> Tutorials </span> </a> <label class="md-nav__link" for="__nav_3"> <span class="md-nav__icon md-icon"></span> </label> </div> <nav aria-expanded="true" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1"> <label class="md-nav__title" for="__nav_3"> <span class="md-nav__icon md-icon"></span> Tutorials </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../"> <span class="md-ellipsis"> Overview </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../spacy101/"> <span class="md-ellipsis"> SpaCy representations </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../matching-a-terminology/"> <span class="md-ellipsis"> Matching a terminology </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../qualifying-entities/"> <span class="md-ellipsis"> Qualifying entities </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../visualization/"> <span class="md-ellipsis"> Visualization </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../detecting-dates/"> <span class="md-ellipsis"> Detecting dates </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../reason/"> <span class="md-ellipsis"> Detecting Reason of Hospitalisation </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../endlines/"> <span class="md-ellipsis"> Detecting end-of-lines </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../aggregating-results/"> <span class="md-ellipsis"> Aggregating results </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../multiple-texts/"> <span class="md-ellipsis"> Processing multiple texts </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../advanced-tutorials/fastapi/"> <span class="md-ellipsis"> Deploying as an API </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../make-a-training-script/"> <span class="md-ellipsis"> Deep-learning tutorial </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../training/"> <span class="md-ellipsis"> Training API </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/> <label class="md-nav__link md-nav__link--active" for="__toc"> <span class="md-ellipsis"> Hyperparameter Tuning </span> <span class="md-nav__icon md-icon"></span> </label> <a class="md-nav__link md-nav__link--active" href="./"> <span class="md-ellipsis"> Hyperparameter Tuning </span> </a> <nav aria-label="Table of contents" class="md-nav md-nav--secondary"> <label class="md-nav__title" for="__toc"> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="#1-creating-a-project"> 1. Creating a project </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#2-tuning-a-model"> 2. Tuning a model </a> <nav aria-label="2. Tuning a model" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#21-tuning-section-in-configyml-file"> 2.1. Tuning Section in config.yml file </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#22-add-hyperparameters-to-tune"> 2.2. Add hyperparameters to tune </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#23-complete-example"> 2.3. Complete Example </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#3-results"> 3. Results </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#4-final-training"> 4. Final Training </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class="md-nav__link" href="../../pipes/"> <span class="md-ellipsis"> Pipes </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../tokenizers/"> <span class="md-ellipsis"> Tokenizers </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class="md-nav__link" href="../../data/"> <span class="md-ellipsis"> Data Connectors </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class="md-nav__link" href="../../concepts/pipeline/"> <span class="md-ellipsis"> Concepts </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class="md-nav__link" href="../../utilities/"> <span class="md-ellipsis"> Utilities </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class="md-nav__link" href="../../reference/edsnlp/"> <span class="md-ellipsis"> Code Reference </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../contributing/"> <span class="md-ellipsis"> Contributing to EDS-NLP </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../changelog/"> <span class="md-ellipsis"> Changelog </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc"> <div class="md-sidebar__scrollwrap"> <div class="md-sidebar__inner"> <nav aria-label="Table of contents" class="md-nav md-nav--secondary"> <label class="md-nav__title" for="__toc"> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="#1-creating-a-project"> 1. Creating a project </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#2-tuning-a-model"> 2. Tuning a model </a> <nav aria-label="2. Tuning a model" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#21-tuning-section-in-configyml-file"> 2.1. Tuning Section in config.yml file </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#22-add-hyperparameters-to-tune"> 2.2. Add hyperparameters to tune </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#23-complete-example"> 2.3. Complete Example </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#3-results"> 3. Results </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#4-final-training"> 4. Final Training </a> </li> </ul> </nav> </div> </div> </div> <div class="md-content" data-md-component="content"> <article class="md-content__inner md-typeset"> <h1 id="hyperparameter-tuning">Hyperparameter Tuning</h1> <p>In this tutorial, we'll see how we can quickly tune hyperparameters of a deep learning model with EDS-NLP using the <code>edsnlp.tune</code> function.</p> <p>Tuning refers to the process of optimizing the hyperparameters of a machine learning model to achieve the best performance. These hyperparameters include factors like learning rate, batch size, dropout rates, and model architecture parameters. Tuning is crucial because the right combination of hyperparameters can significantly improve model accuracy and efficiency, while poor choices can lead to overfitting, underfitting, or unnecessary computational costs. By systematically searching for the best hyperparameters, we ensure the model is both effective and efficient before the final training phase.</p> <p>We strongly suggest you read the previous <a href="../training/">"Training API tutorial"</a> to understand how to train a deep learning model using a config file with EDS-NLP.</p> <h2 id="1-creating-a-project">1. Creating a project</h2> <p>If you already have installed <code>edsnlp[ml]</code> and do not want to setup a project, you can skip to the <a href="#tuning-the-model">next section</a>.</p> <p>Create a new project:</p> <div class="highlight" data-md-color-scheme="slate"><pre><span></span><code>mkdir<span class="w"> </span>my_ner_project
<span class="nb">cd</span><span class="w"> </span>my_ner_project

touch<span class="w"> </span>README.md<span class="w"> </span>pyproject.toml
mkdir<span class="w"> </span>-p<span class="w"> </span>configs<span class="w"> </span>data/dataset
</code></pre></div> <p>Add a standard <code>pyproject.toml</code> file with the following content. This file will be used to manage the dependencies of the project and its versioning.</p> <div class="highlight"><span class="filename">pyproject.toml</span><pre><span></span><code><span class="k">[project]</span>
<span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"my_ner_project"</span>
<span class="n">version</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"0.1.0"</span>
<span class="n">description</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">""</span>
<span class="n">authors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="n">name</span><span class="p">=</span><span class="s2">"Firstname Lastname"</span><span class="p">,</span><span class="w"> </span><span class="n">email</span><span class="p">=</span><span class="s2">"firstname.lastname@domain.com"</span><span class="w"> </span><span class="p">}</span>
<span class="p">]</span>
<span class="n">readme</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"README.md"</span>
<span class="n">requires-python</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"&gt;3.7.1,&lt;4.0"</span>

<span class="n">dependencies</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">"edsnlp[ml]&gt;=0.16.0"</span><span class="p">,</span>
<span class="w">    </span><span class="s2">"sentencepiece&gt;=0.1.96"</span><span class="p">,</span>
<span class="w">    </span><span class="s2">"optuna&gt;=4.0.0"</span><span class="p">,</span>
<span class="w">    </span><span class="s2">"plotly&gt;=5.18.0"</span><span class="p">,</span>
<span class="w">    </span><span class="s2">"ruamel.yaml&gt;=0.18.0"</span><span class="p">,</span>
<span class="w">    </span><span class="s2">"configobj&gt;=5.0.9"</span><span class="p">,</span>
<span class="p">]</span>

<span class="k">[project.optional-dependencies]</span>
<span class="n">dev</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">"dvc&gt;=2.37.0; python_version &gt;= '3.8'"</span><span class="p">,</span>
<span class="w">    </span><span class="s2">"pandas&gt;=1.1.0,&lt;2.0.0; python_version &lt; '3.8'"</span><span class="p">,</span>
<span class="w">    </span><span class="s2">"pandas&gt;=1.4.0,&lt;2.0.0; python_version &gt;= '3.8'"</span><span class="p">,</span>
<span class="w">    </span><span class="s2">"pre-commit&gt;=2.18.1"</span><span class="p">,</span>
<span class="w">    </span><span class="s2">"accelerate&gt;=0.21.0; python_version &gt;= '3.8'"</span><span class="p">,</span>
<span class="w">    </span><span class="s2">"rich-logger&gt;=0.3.0"</span>
<span class="p">]</span>
</code></pre></div> <p>We recommend using a virtual environment ("venv") to isolate the dependencies of your project and using <a href="https://docs.astral.sh/uv/">uv</a> to install the dependencies:</p> <div class="highlight" data-md-color-scheme="slate"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>uv
<span class="c1"># skip the next two lines if you do not want a venv</span>
uv<span class="w"> </span>venv<span class="w"> </span>.venv
<span class="nb">source</span><span class="w"> </span>.venv/bin/activate
uv<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span><span class="s2">".[dev]"</span><span class="w"> </span>-p<span class="w"> </span><span class="k">$(</span>uv<span class="w"> </span>python<span class="w"> </span>find<span class="k">)</span>
</code></pre></div> <h2 id="2-tuning-a-model">2. Tuning a model</h2> <h3 id="21-tuning-section-in-configyml-file">2.1. Tuning Section in <code>config.yml</code> file</h3> <p>If you followed the <a href="../training/">"Training API tutorial"</a>, you should already have a <code>configs/config.yml</code> file for training parameters.</p> <p>To enable hyperparameter tuning, add the following <code>tuning</code> section to your <code>config.yml</code> file:</p> <div class="highlight"><span class="filename">configs/config.yml</span><pre><span></span><code><span class="nt">tuning</span><span class="p">:</span>
<span class="w">  </span><span class="c1"># Output directory for tuning results.</span>
<span class="w">  </span><span class="nt">output_dir</span><span class="p">:</span><span class="w"> </span><span class="s">'results'</span>
<span class="w">  </span><span class="c1"># Checkpoint directory</span>
<span class="w">  </span><span class="nt">checkpoint_dir</span><span class="p">:</span><span class="w"> </span><span class="s">'checkpoint'</span>
<span class="w">  </span><span class="c1"># Number of gpu hours allowed for tuning.</span>
<span class="w">  </span><span class="nt">gpu_hours</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0</span>
<span class="w">  </span><span class="c1"># Number of fixed trials to tune hyperparameters (override gpu_hours).</span>
<span class="w">  </span><span class="nt">n_trials</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span>
<span class="w">  </span><span class="c1"># Enable two-phase tuning. In the first phase, the script will tune all hyperparameters.</span>
<span class="w">  </span><span class="c1"># In the second phase, it will focus only on the top 50% most important hyperparameters.</span>
<span class="w">  </span><span class="nt">two_phase_tuning</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="w">  </span><span class="c1"># Metric used to evaluate trials.</span>
<span class="w">  </span><span class="nt">metric</span><span class="p">:</span><span class="w"> </span><span class="s">"ner.micro.f"</span>
<span class="w">  </span><span class="c1"># Hyperparameters to tune.</span>
<span class="w">  </span><span class="nt">hyperparameters</span><span class="p">:</span>
</code></pre></div> <p>Let's detail the new parameters:</p> <ul> <li><code>output_dir</code>: Directory where tuning results, visualizations, and best parameters will be saved.</li> <li><code>checkpoint_dir</code>: Directory where the tuning checkpoint <code>study.pkl</code> will be saved each trial. This enables automatic resumption of tuning in case of a crash. To disable resumption, simply delete the <code>study.pkl</code> file.</li> <li><code>gpu_hours</code>: Estimated total GPU time available for tuning, in hours. Given this time, the script will automatically compute for how many training trials we can tune hyperparameters. By default, <code>gpu_hours</code> is set to 1.</li> <li><code>n_trials</code>: Number of training trials for tuning. If provided, it will override <code>gpu_hours</code> and tune the model for exactly <code>n_trial</code> trials.</li> <li><code>two_phase_tuning</code>: If True, performs a two-phase tuning. In the first phase, all hyperparameters are tuned, and in the second phase, the top half (based on importance) are fine-tuned while freezing others. By default, <code>two_phase_tuning</code> is False.</li> <li><code>metric</code>: Metric used to evaluate trials. It corresponds to a path in the scorer results (depending on the scorer used in the config). By default <code>metric</code> is set to "ner.micro.f".</li> <li><code>hyperparameters</code>: The list of hyperparameters to tune and details about their tunings. We will discuss how it work in the following section.</li> </ul> <h3 id="22-add-hyperparameters-to-tune">2.2. Add hyperparameters to tune</h3> <p>In the <code>config.yml</code> file, the <code>tuning.hyperparameters</code> section defines the hyperparameters to optimize. Each hyperparameter can be specified with its type, range, and additional properties. To add a hyperparameter, follow this syntax:</p> <div class="highlight"><span class="filename">configs/config.yml</span><pre><span></span><code><span class="nt">tuning</span><span class="p">:</span>
<span class="w">  </span><span class="nt">hyperparameters</span><span class="p">:</span>
<span class="w">    </span><span class="c1"># Hyperparameter path in `config.yml`.</span>
<span class="w">    </span><span class="s">"nlp.components.ner.embedding.embedding.classifier_dropout"</span><span class="p p-Indicator">:</span>
<span class="w">      </span><span class="c1"># Alias name. If not specified, full path will be the name.</span>
<span class="w">      </span><span class="nt">alias</span><span class="p">:</span><span class="w"> </span><span class="s">"classifier_dropout"</span>
<span class="w">      </span><span class="c1"># Type of the hyperparameter: 'int', 'float', or 'categorical'.</span>
<span class="w">      </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="s">"float"</span>
<span class="w">      </span><span class="c1"># Lower bound for tuning.</span>
<span class="w">      </span><span class="nt">low</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.</span>
<span class="w">      </span><span class="c1"># Upper bound for tuning.</span>
<span class="w">      </span><span class="nt">high</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.3</span>
<span class="w">      </span><span class="c1"># Step for discretization (optional).</span>
<span class="w">      </span><span class="nt">step</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.05</span>
</code></pre></div> <p>Since <code>edsnlp.tune</code> leverages the <a href="https://optuna.org/">Optuna</a> framework, we recommend reviewing the following Optuna functions to understand the properties you can specify for hyperparameter sampling:</p> <ul> <li><a href="https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html#optuna.trial.Trial.suggest_float">suggest_float</a> ‚Äì For sampling floating-point hyperparameters.</li> <li><a href="https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html#optuna.trial.Trial.suggest_int">suggest_int</a> ‚Äì For sampling integer hyperparameters.</li> <li><a href="https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html#optuna.trial.Trial.suggest_categorical">suggest_categorical</a> ‚Äì For sampling categorical hyperparameters.</li> </ul> <p>These resources provide detailed guidance on defining the sampling ranges, distributions, and additional properties for each type of hyperparameter.</p> <h3 id="23-complete-example">2.3. Complete Example</h3> <p>Now, let's look at a complete example. Assume that we want to perform a two-phase tuning, for 40 gpu hours, on the following hyperparameters:</p> <ul> <li><code>hidden_dropout_prob</code>: Dropout probability for hidden layers.</li> <li><code>attention_dropout_prob</code>: Dropout probability for attention layers.</li> <li><code>classifier_dropout</code>: Dropout probability for the classifier layer.</li> <li><code>transformer_start_value</code>: Learning rate start value for the transformer.</li> <li><code>transformer_max_value</code>: Maximum learning rate for the transformer.</li> <li><code>transformer_warmup_rate</code>: Warmup rate for the transformer learning rate scheduler.</li> <li><code>transformer_weight_decay</code>: Weight decay for the transformer optimizer.</li> <li><code>other_start_value</code>: Learning rate start value for other components.</li> <li><code>other_max_value</code>: Maximum learning rate for other components.</li> <li><code>other_warmup_rate</code>: Warmup rate for the learning rate scheduler of other components.</li> <li><code>other_weight_decay</code>: Weight decay for the optimizer of other components.</li> </ul> <p>Then the full <code>config.yml</code> will be:</p> <div class="highlight"><span class="filename">configs/config.yml</span><pre><span></span><code><span class="nt">vars</span><span class="p">:</span>
<span class="w">  </span><span class="nt">train</span><span class="p">:</span><span class="w"> </span><span class="s">'./data/dataset/train'</span>
<span class="w">  </span><span class="nt">dev</span><span class="p">:</span><span class="w"> </span><span class="s">'./data/dataset/test'</span>

<span class="c1"># ü§ñ PIPELINE DEFINITION</span>
<span class="nt">nlp</span><span class="p">:</span>
<span class="w">  </span><span class="s">'@core'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pipeline</span>
<span class="w">  </span><span class="nt">lang</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">eds</span><span class="w">  </span><span class="c1"># Word-level tokenization: use the "eds" tokenizer</span>
<span class="w">  </span><span class="nt">components</span><span class="p">:</span>
<span class="w">    </span><span class="nt">ner</span><span class="p">:</span>
<span class="w">      </span><span class="s">'@factory'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain"><a href="../../pipes/trainable/ner/#edsnlp.pipes.trainable.ner_crf.factory.create_component">eds.ner_crf</a></span>
<span class="w">      </span><span class="nt">mode</span><span class="p">:</span><span class="w"> </span><span class="s">'joint'</span>
<span class="w">      </span><span class="nt">target_span_getter</span><span class="p">:</span><span class="w"> </span><span class="s">'gold_spans'</span>
<span class="w">      </span><span class="nt">span_setter</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="w"> </span><span class="s">"ents"</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">"*"</span><span class="w"> </span><span class="p p-Indicator">]</span>
<span class="w">      </span><span class="nt">infer_span_setter</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">      </span><span class="nt">embedding</span><span class="p">:</span>
<span class="w">        </span><span class="s">'@factory'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain"><a href="../../pipes/trainable/embeddings/text_cnn/#edsnlp.pipes.trainable.embeddings.text_cnn.factory.create_component">eds.text_cnn</a></span>
<span class="w">        </span><span class="nt">kernel_sizes</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="w"> </span><span class="nv">3</span><span class="w"> </span><span class="p p-Indicator">]</span>
<span class="w">        </span><span class="nt">embedding</span><span class="p">:</span>
<span class="w">          </span><span class="s">'@factory'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain"><a href="../../pipes/trainable/embeddings/transformer/#edsnlp.pipes.trainable.embeddings.transformer.factory.create_component">eds.transformer</a></span>
<span class="w">          </span><span class="nt">model</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">prajjwal1/bert-tiny</span>
<span class="w">          </span><span class="nt">ignore_mismatched_sizes</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="w">          </span><span class="nt">window</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">128</span>
<span class="w">          </span><span class="nt">stride</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">96</span>
<span class="w">          </span><span class="c1"># Dropout parameters passed to the underlying transformer object.</span>
<span class="w">          </span><span class="nt">hidden_dropout_prob</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">          </span><span class="nt">attention_probs_dropout_prob</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">          </span><span class="nt">classifier_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>

<span class="c1"># üìà SCORERS</span>
<span class="nt">scorer</span><span class="p">:</span>
<span class="w">  </span><span class="nt">ner</span><span class="p">:</span>
<span class="w">    </span><span class="s">'@metrics'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">eds.ner_token</span>
<span class="w">    </span><span class="nt">span_getter</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ nlp.components.ner.target_span_getter }</span>

<span class="c1"># üéõÔ∏è OPTIMIZER</span>
<span class="nt">optimizer</span><span class="p">:</span>
<span class="w">  </span><span class="s">"@core"</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">optimizer</span>
<span class="w">  </span><span class="nt">optim</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">adamw</span>
<span class="w">  </span><span class="nt">groups</span><span class="p">:</span>
<span class="w">    </span><span class="s">"^transformer"</span><span class="p p-Indicator">:</span>
<span class="w">      </span><span class="nt">weight_decay</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-3</span>
<span class="w">      </span><span class="nt">lr</span><span class="p">:</span>
<span class="w">        </span><span class="s">'@schedules'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">linear</span>
<span class="w">        </span><span class="s">"warmup_rate"</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">        </span><span class="s">"start_value"</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-5</span>
<span class="w">        </span><span class="s">"max_value"</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8e-5</span>
<span class="w">    </span><span class="s">".*"</span><span class="p p-Indicator">:</span>
<span class="w">      </span><span class="nt">weight_decay</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-3</span>
<span class="w">      </span><span class="nt">lr</span><span class="p">:</span>
<span class="w">        </span><span class="s">'@schedules'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">linear</span>
<span class="w">        </span><span class="s">"warmup_rate"</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">        </span><span class="s">"start_value"</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-5</span>
<span class="w">        </span><span class="s">"max_value"</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8e-5</span>
<span class="w">  </span><span class="nt">module</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ nlp }</span>
<span class="w">  </span><span class="nt">total_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ train.max_steps }</span>

<span class="c1"># üìö DATA</span>
<span class="nt">train_data</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">data</span><span class="p">:</span>
<span class="w">      </span><span class="s">'@readers'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">standoff</span>
<span class="w">      </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ vars.train }</span>
<span class="w">      </span><span class="nt">converter</span><span class="p">:</span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">'@factory'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain"><a href="../../data/converters/#edsnlp.data.converters.StandoffDict2DocConverter">eds.standoff_dict2doc</a></span>
<span class="w">          </span><span class="nt">span_setter</span><span class="p">:</span><span class="w"> </span><span class="s">'gold_spans'</span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">'@factory'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain"><a href="../../pipes/misc/split/#edsnlp.pipes.misc.split.split.Split">eds.split</a></span>
<span class="w">          </span><span class="nt">nlp</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">          </span><span class="nt">max_length</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">          </span><span class="nt">regex</span><span class="p">:</span><span class="w"> </span><span class="s">'\n\n+'</span>
<span class="w">    </span><span class="nt">shuffle</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dataset</span>
<span class="w">    </span><span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">32 * 128 tokens</span>
<span class="w">    </span><span class="nt">pipe_names</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="w"> </span><span class="s">"ner"</span><span class="w"> </span><span class="p p-Indicator">]</span>

<span class="nt">val_data</span><span class="p">:</span>
<span class="w">  </span><span class="s">'@readers'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">standoff</span>
<span class="w">  </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ vars.dev }</span>
<span class="w">  </span><span class="nt">converter</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">'@factory'</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain"><a href="../../data/converters/#edsnlp.data.converters.StandoffDict2DocConverter">eds.standoff_dict2doc</a></span>
<span class="w">      </span><span class="nt">span_setter</span><span class="p">:</span><span class="w"> </span><span class="s">'gold_spans'</span>

<span class="c1"># üöÄ TRAIN SCRIPT OPTIONS</span>
<span class="c1"># -&gt; python -m edsnlp.train --config configs/config.yml</span>
<span class="nt">train</span><span class="p">:</span>
<span class="w">  </span><span class="nt">nlp</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ nlp }</span>
<span class="w">  </span><span class="nt">logger</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="w">  </span><span class="nt">output_dir</span><span class="p">:</span><span class="w"> </span><span class="s">'artifacts'</span>
<span class="w">  </span><span class="nt">train_data</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ train_data }</span>
<span class="w">  </span><span class="nt">val_data</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ val_data }</span>
<span class="w">  </span><span class="nt">max_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">400</span>
<span class="w">  </span><span class="nt">validation_interval</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ train.max_steps//2 }</span>
<span class="w">  </span><span class="nt">max_grad_norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0</span>
<span class="w">  </span><span class="nt">scorer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ scorer }</span>
<span class="w">  </span><span class="nt">optimizer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ optimizer }</span>
<span class="w">  </span><span class="nt">num_workers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>

<span class="c1"># üì¶ PACKAGE SCRIPT OPTIONS</span>
<span class="c1"># -&gt; python -m edsnlp.package --config configs/config.yml</span>
<span class="nt">package</span><span class="p">:</span>
<span class="w">  </span><span class="nt">pipeline</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ train.output_dir }</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s">'my_ner_model'</span>

<span class="c1"># ‚öôÔ∏è TUNE SCRIPT OPTIONS</span>
<span class="c1"># -&gt; python -m edsnlp.tune --config configs/config.yml</span>
<span class="nt">tuning</span><span class="p">:</span>
<span class="w">  </span><span class="nt">output_dir</span><span class="p">:</span><span class="w"> </span><span class="s">'results'</span>
<span class="w">  </span><span class="nt">checkpoint_dir</span><span class="p">:</span><span class="w"> </span><span class="s">'checkpoint'</span>
<span class="w">  </span><span class="nt">gpu_hours</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">40.0</span>
<span class="w">  </span><span class="nt">two_phase_tuning</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="w">  </span><span class="nt">metric</span><span class="p">:</span><span class="w"> </span><span class="s">"ner.micro.f"</span>
<span class="w">  </span><span class="nt">hyperparameters</span><span class="p">:</span>
<span class="w">    </span><span class="s">"nlp.components.ner.embedding.embedding.hidden_dropout_prob"</span><span class="p p-Indicator">:</span>
<span class="w">      </span><span class="nt">alias</span><span class="p">:</span><span class="w"> </span><span class="s">"hidden_dropout"</span>
<span class="w">      </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="s">"float"</span>
<span class="w">      </span><span class="nt">low</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.</span>
<span class="w">      </span><span class="nt">high</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.3</span>
<span class="w">      </span><span class="nt">step</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.05</span>
<span class="w">    </span><span class="s">"nlp.components.ner.embedding.embedding.attention_probs_dropout_prob"</span><span class="p p-Indicator">:</span>
<span class="w">      </span><span class="nt">alias</span><span class="p">:</span><span class="w"> </span><span class="s">"attention_dropout"</span>
<span class="w">      </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="s">"float"</span>
<span class="w">      </span><span class="nt">low</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.</span>
<span class="w">      </span><span class="nt">high</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.3</span>
<span class="w">      </span><span class="nt">step</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.05</span>
<span class="w">    </span><span class="s">"nlp.components.ner.embedding.embedding.classifier_dropout"</span><span class="p p-Indicator">:</span>
<span class="w">      </span><span class="nt">alias</span><span class="p">:</span><span class="w"> </span><span class="s">"classifier_dropout"</span>
<span class="w">      </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="s">"float"</span>
<span class="w">      </span><span class="nt">low</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.</span>
<span class="w">      </span><span class="nt">high</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.3</span>
<span class="w">      </span><span class="nt">step</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.05</span>
<span class="w">    </span><span class="s">"optimizer.groups.^transformer.lr.start_value"</span><span class="p p-Indicator">:</span>
<span class="w">      </span><span class="nt">alias</span><span class="p">:</span><span class="w"> </span><span class="s">"transformer_start_value"</span>
<span class="w">      </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="s">"float"</span>
<span class="w">      </span><span class="nt">low</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-6</span>
<span class="w">      </span><span class="nt">high</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-3</span>
<span class="w">      </span><span class="nt">log</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="w">    </span><span class="s">"optimizer.groups.^transformer.lr.max_value"</span><span class="p p-Indicator">:</span>
<span class="w">      </span><span class="nt">alias</span><span class="p">:</span><span class="w"> </span><span class="s">"transformer_max_value"</span>
<span class="w">      </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="s">"float"</span>
<span class="w">      </span><span class="nt">low</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-6</span>
<span class="w">      </span><span class="nt">high</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-3</span>
<span class="w">      </span><span class="nt">log</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="w">    </span><span class="s">"optimizer.groups.^transformer.lr.warmup_rate"</span><span class="p p-Indicator">:</span>
<span class="w">      </span><span class="nt">alias</span><span class="p">:</span><span class="w"> </span><span class="s">"transformer_warmup_rate"</span>
<span class="w">      </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="s">"float"</span>
<span class="w">      </span><span class="nt">low</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.</span>
<span class="w">      </span><span class="nt">high</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.3</span>
<span class="w">      </span><span class="nt">step</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.05</span>
<span class="w">    </span><span class="s">"optimizer.groups.^transformer.weight_decay"</span><span class="p p-Indicator">:</span>
<span class="w">      </span><span class="nt">alias</span><span class="p">:</span><span class="w"> </span><span class="s">"transformer_weight_decay"</span>
<span class="w">      </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="s">"float"</span>
<span class="w">      </span><span class="nt">low</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-4</span>
<span class="w">      </span><span class="nt">high</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-2</span>
<span class="w">      </span><span class="nt">log</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="w">    </span><span class="s">"optimizer.groups.'.*'.lr.warmup_rate"</span><span class="p p-Indicator">:</span>
<span class="w">      </span><span class="nt">alias</span><span class="p">:</span><span class="w"> </span><span class="s">"other_warmup_rate"</span>
<span class="w">      </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="s">"float"</span>
<span class="w">      </span><span class="nt">low</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.</span>
<span class="w">      </span><span class="nt">high</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.3</span>
<span class="w">      </span><span class="nt">step</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.05</span>
<span class="w">    </span><span class="s">"optimizer.groups.'.*'.lr.start_value"</span><span class="p p-Indicator">:</span>
<span class="w">      </span><span class="nt">alias</span><span class="p">:</span><span class="w"> </span><span class="s">"other_start_value"</span>
<span class="w">      </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="s">"float"</span>
<span class="w">      </span><span class="nt">low</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-6</span>
<span class="w">      </span><span class="nt">high</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-3</span>
<span class="w">      </span><span class="nt">log</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="w">    </span><span class="s">"optimizer.groups.'.*'.lr.max_value"</span><span class="p p-Indicator">:</span>
<span class="w">      </span><span class="nt">alias</span><span class="p">:</span><span class="w"> </span><span class="s">"other_max_value"</span>
<span class="w">      </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="s">"float"</span>
<span class="w">      </span><span class="nt">low</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-6</span>
<span class="w">      </span><span class="nt">high</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-3</span>
<span class="w">      </span><span class="nt">log</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
<span class="w">    </span><span class="s">"optimizer.groups.'.*'.weight_decay"</span><span class="p p-Indicator">:</span>
<span class="w">      </span><span class="nt">alias</span><span class="p">:</span><span class="w"> </span><span class="s">"other_weight_decay"</span>
<span class="w">      </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="s">"float"</span>
<span class="w">      </span><span class="nt">low</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-4</span>
<span class="w">      </span><span class="nt">high</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-2</span>
<span class="w">      </span><span class="nt">log</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">True</span>
</code></pre></div> <p>Finally, to lauch the tuning process, use the following command:</p> <div class="highlight" data-md-color-scheme="slate"><pre><span></span><code>python<span class="w"> </span>-m<span class="w"> </span>edsnlp.tune<span class="w"> </span>--config<span class="w"> </span>configs/config.yml<span class="w"> </span>--seed<span class="w"> </span><span class="m">42</span>
</code></pre></div> <h2 id="3-results">3. Results</h2> <p>At the end of the tuning process, <code>edsnlp.tune</code> generates various results and saves them in the <code>output_dir</code> specified in the <code>config.yml</code> file:</p> <ul> <li><strong>Tuning Summary</strong>: <code>result_summary.txt</code>, a summary file containing details about the best training trial, the best overall metric, the optimal hyperparameter values, and the average importance of each hyperparameter across all trials.</li> <li><strong>Optimal Configuration</strong>: <code>config.yml</code>, containing the best hyperparameter values.</li> <li><strong>Graphs and Visualizations</strong>: Various graphics illustrating the tuning process, such as:</li> <li><a href="https://optuna.readthedocs.io/en/stable/reference/visualization/generated/optuna.visualization.plot_optimization_history.html#sphx-glr-reference-visualization-generated-optuna-visualization-plot-optimization-history-py"><strong>Optimization History plot</strong></a>: A line graph showing the performance of each trial over time, illustrating the optimization process and how the model's performance improves with each iteration.</li> <li><a href="https://optuna.readthedocs.io/en/stable/reference/visualization/generated/optuna.visualization.plot_edf.html#sphx-glr-reference-visualization-generated-optuna-visualization-plot-edf-py"><strong>Empirical Distribution Function (EDF) plot</strong></a>: A graph showing the cumulative distribution of the results, helping you understand the distribution of performance scores and providing insights into the variability and robustness of the tuning process.</li> <li><a href="https://optuna.readthedocs.io/en/stable/reference/visualization/generated/optuna.visualization.plot_contour.html#sphx-glr-reference-visualization-generated-optuna-visualization-plot-contour-py"><strong>Contour plot</strong></a>: A 2D plot that shows the relationship between two hyperparameters and their combined effect on the objective metric, providing a clear view of the optimal parameter regions.</li> <li><a href="https://optuna.readthedocs.io/en/stable/reference/visualization/generated/optuna.visualization.plot_parallel_coordinate.html#sphx-glr-reference-visualization-generated-optuna-visualization-plot-parallel-coordinate-py"><strong>Parallel Coordinate plot</strong></a>: A multi-dimensional plot where each hyperparameter is represented as a vertical axis, and each trial is displayed as a line connecting the hyperparameter values, helping you analyze correlations and patterns across hyperparameters and their impact on performance.</li> <li><a href="https://optuna.readthedocs.io/en/stable/reference/visualization/generated/optuna.visualization.plot_timeline.html#sphx-glr-reference-visualization-generated-optuna-visualization-plot-timeline-py"><strong>Timeline plot</strong></a>: A 2D plot that displays all trials and their statuses ("completed," "pruned," or "failed") over time, providing a clear overview of the progress and outcomes of the tuning process.</li> </ul> <p>These outputs offer a comprehensive view of the tuning results, enabling you to better understand the optimization process and easily deploy the best configuration.</p> <p><strong>Note</strong>: If you enabled two-phase tuning, the <code>output_dir</code> will contain two subdirectories, <code>phase_1</code> and <code>phase_2</code>, each with their own result files as described earlier. This separation allows you to analyze the results from each phase individually.</p> <h2 id="4-final-training">4. Final Training</h2> <p>Now that the hyperparameters have been tuned, you can update your final <code>config.yml</code> with the best-performing hyperparameters and proceed to launch the final training using the <a href="../training/">"Training API"</a>.</p> <div class="footnote"><hr/><ol></ol></div> <script async="" crossorigin="anonymous" data-category="Announcements" data-category-id="DIC_kwDOG97JnM4CkS1h" data-emit-metadata="0" data-input-position="bottom" data-lang="en" data-mapping="title" data-reactions-enabled="1" data-repo="aphp/edsnlp" data-repo-id="R_kgDOG97JnA" data-strict="0" data-theme="https://aphp.github.io/edsnlp/master/assets/stylesheets/giscus_light.css" loading="lazy" src="https://giscus.app/client.js">
</script> <script>
    var giscus = document.querySelector("script[src*=giscus]")

    // Set palette on initial load
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
        var theme = palette.color.scheme === "slate"
            ? "https://aphp.github.io/edsnlp/master/assets/stylesheets/giscus_dark.css"
            : "https://aphp.github.io/edsnlp/master/assets/stylesheets/giscus_light.css"

        // Instruct Giscus to set theme
        giscus.setAttribute("data-theme", theme)
    }

    // Register event handlers after documented loaded
    document.addEventListener("DOMContentLoaded", function () {
        var ref = document.querySelector("[data-md-component=palette]")
        ref.addEventListener("change", function () {
            var palette = __md_get("__palette")
            if (palette && typeof palette.color === "object") {
                var theme = palette.color.scheme === "slate"
                    ? "https://aphp.github.io/edsnlp/master/assets/stylesheets/giscus_dark.css"
                    : "https://aphp.github.io/edsnlp/master/assets/stylesheets/giscus_light.css"

                // Instruct Giscus to change theme
                var frame = document.querySelector(".giscus-frame")
                frame.contentWindow.postMessage(
                    {giscus: {setConfig: {theme}}},
                    "https://giscus.app"
                )
            }
        })
    })
</script> </article> </div> </div> <button class="md-top md-icon" data-md-component="top" hidden="" type="button"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"></path></svg> Back to top </button> </main> <footer class="md-footer"> <nav aria-label="Footer" class="md-footer__inner md-grid"> <a aria-label="Previous: Training API" class="md-footer__link md-footer__link--prev" href="../training/" rel="prev"> <div class="md-footer__button md-icon"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg> </div> <div class="md-footer__title"> <span class="md-footer__direction"> Previous </span> <div class="md-ellipsis"> Training API </div> </div> </a> <a aria-label="Next: Overview" class="md-footer__link md-footer__link--next" href="../../pipes/" rel="next"> <div class="md-footer__title"> <span class="md-footer__direction"> Next </span> <div class="md-ellipsis"> Overview </div> </div> <div class="md-footer__button md-icon"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"></path></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class="md-copyright"> Made with <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank"> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class="md-dialog" data-md-component="dialog"> <div class="md-dialog__inner md-typeset"></div> </div> <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tracking", "navigation.instant", "navigation.indexes", "navigation.prune", "navigation.top", "navigation.footer", "content.code.annotate", "content.code.copy", "announce.dismiss"], "search": "../../assets/javascripts/workers/search.dfff1995.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "latest", "provider": "mike"}}</script> <script src="../../assets/javascripts/bundle.dff1b7c8.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/vega@5"></script> <script src="https://cdn.jsdelivr.net/npm/vega-lite@5"></script> <script src="https://cdn.jsdelivr.net/npm/vega-embed@6"></script> <script src="../../assets/termynal/termynal.js"></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> </body> </html>