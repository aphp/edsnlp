<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel=icon href=../assets/logo/edsnlp.svg><meta name=generator content="mkdocs-1.5.2, mkdocs-material-9.2.8"><title>Training models with EDS-NLP - EDS-NLP</title><link rel=stylesheet href=../assets/stylesheets/main.046329b4.min.css><link rel=stylesheet href=../assets/stylesheets/palette.85d0ee34.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../assets/_mkdocstrings.css><link rel=stylesheet href=../assets/stylesheets/extra.css><link rel=stylesheet href=../assets/stylesheets/cards.css><link rel=stylesheet href=../assets/termynal/termynal.css><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href="#training-models-with-eds-nlp" class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> </div> <header class="md-header md-header--shadow" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=".." title=EDS-NLP class="md-header__button md-logo" aria-label=EDS-NLP data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> EDS-NLP </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Training models with EDS-NLP </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg> </label> </form> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href="https://github.com/aphp/edsnlp" title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> aphp/edsnlp </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=".." title=EDS-NLP class="md-nav__button md-logo" aria-label=EDS-NLP data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg> </a> EDS-NLP </label> <div class=md-nav__source> <a href="https://github.com/aphp/edsnlp" title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> aphp/edsnlp </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=".." class=md-nav__link> <span class=md-ellipsis> Getting started </span> </a> </li> <li class=md-nav__item> <a href="https://aphp.github.io/edsnlp/demo" target=_blank class=md-nav__link> <span class=md-ellipsis> Demo </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href="../tutorials/overview/" class=md-nav__link> <span class=md-ellipsis> Tutorials </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href="../pipelines/overview/" class=md-nav__link> <span class=md-ellipsis> Pipes </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class=md-nav__item> <a href="../tokenizers/" class=md-nav__link> <span class=md-ellipsis> Tokenizers </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href="../utilities/connectors/overview/" class=md-nav__link> <span class=md-ellipsis> Connectors </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href="../concepts/pipeline/" class=md-nav__link> <span class=md-ellipsis> Concepts </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href="../utilities/overview/" class=md-nav__link> <span class=md-ellipsis> Utilities </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href="../reference/edsnlp/" class=md-nav__link> <span class=md-ellipsis> Code Reference </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class=md-nav__item> <a href="../contributing/" class=md-nav__link> <span class=md-ellipsis> Contributing to EDS-NLP </span> </a> </li> <li class=md-nav__item> <a href="../changelog/" class=md-nav__link> <span class=md-ellipsis> Changelog </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href="#how-do-we-compose-models" class=md-nav__link> How do we compose models ? </a> </li> <li class=md-nav__item> <a href="#anatomy-of-components" class=md-nav__link> Anatomy of components </a> <nav class=md-nav aria-label="Anatomy of components"> <ul class=md-nav__list> <li class=md-nav__item> <a href="#methods" class=md-nav__link> Methods </a> </li> <li class=md-nav__item> <a href="#examples" class=md-nav__link> Examples: </a> </li> <li class=md-nav__item> <a href="#classes" class=md-nav__link> Classes </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href="#the-initialization-conundrum" class=md-nav__link> The initialization conundrum </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=training-models-with-eds-nlp>Training models with EDS-NLP</h1> <h3 id=how-do-we-compose-models>How do we compose models ?</h3> <blockquote> <p>Problem: we can't initialize a module before knowing its input size Since input size (as well as other key parameters) can depend on the data, we can't directly instantiate a module from the config before the data has been seen in post_init</p> </blockquote> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>torch.nn</span>


<span class=k>class</span> <span class=nc>TransformerEncoder</span><span class=p>(</span><span class=n>Component</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_name</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>transformer</span> <span class=o>=</span> <span class=n>AutoModel</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_name</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>AutoTokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_name</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>preprocess</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>doc</span><span class=p>):</span>
        <span class=k>return</span> <span class=p>{</span><span class=o>...</span><span class=p>}</span>

    <span class=k>def</span> <span class=nf>collate</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>):</span>
        <span class=k>return</span> <span class=p>{</span><span class=o>...</span><span class=p>}</span>

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>):</span>
        <span class=k>return</span> <span class=p>{</span><span class=o>...</span><span class=p>}</span>

    <span class=k>def</span> <span class=nf>postprocess</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>):</span>
        <span class=k>return</span> <span class=p>{</span><span class=o>...</span><span class=p>}</span>
</code></pre></div> <p>To compose a Transformer with a TextCNN encoder, we have multiple options:</p> <ol> <li><strong>module-in-component</strong>: a <code>TextCNN</code> standard (<code>torch.nn.Module</code>), instantiated in <code>post_init</code>, by a <code>TextCNNEncoder</code> (<code>Component</code>):</li> </ol> <div class=highlight><pre><span></span><code><span class=nd>@modules</span><span class=o>.</span><span class=n>register</span><span class=p>(</span><span class=s2>&quot;text-cnn&quot;</span><span class=p>)</span>
<span class=k>class</span> <span class=nc>TextCNN</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>kernel_sizes</span><span class=p>,</span> <span class=n>input_size</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>kernel_sizes</span> <span class=o>=</span> <span class=n>kernel_sizes</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>convs</span> <span class=o>=</span> <span class=o>...</span>

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>embeddings</span><span class=p>,</span> <span class=n>mask</span><span class=p>):</span>
        <span class=k>return</span> <span class=n>reshape</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>convs</span><span class=p>(</span><span class=n>embeddings</span><span class=p>))</span> <span class=o>+</span> <span class=n>mask</span>

<span class=c1># And now create a TextCNN module</span>
<span class=nd>@register</span><span class=p>(</span><span class=s2>&quot;text-cnn&quot;</span><span class=p>)</span>
<span class=k>class</span> <span class=nc>TextCNNEncoder</span><span class=p>(</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>embedding</span><span class=p>,</span> <span class=n>kernel_sizes</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>kernel_sizes</span> <span class=o>=</span> <span class=n>kernel_sizes</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span> <span class=o>=</span> <span class=n>embedding</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>module</span> <span class=o>=</span> <span class=kc>None</span>

    <span class=k>def</span> <span class=nf>post_init</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=o>.</span><span class=n>post_init</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
        <span class=c1># We can now initialize the module</span>
        <span class=n>size</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=o>.</span><span class=n>output_size</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>text_cnn</span> <span class=o>=</span> <span class=n>TextCNN</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>kernel_sizes</span><span class=p>,</span> <span class=n>size</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>preprocess</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>):</span>
        <span class=k>return</span> <span class=p>{</span><span class=s2>&quot;embedding&quot;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=o>.</span><span class=n>preprocess</span><span class=p>(</span><span class=n>batch</span><span class=p>)}</span>

    <span class=k>def</span> <span class=nf>collate</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>return</span> <span class=p>{</span><span class=o>...</span><span class=p>}</span>

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>):</span>
        <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=p>(</span><span class=n>batch</span><span class=p>[</span><span class=s2>&quot;embedding&quot;</span><span class=p>])</span>
        <span class=n>embeddings</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>text_cnn</span><span class=p>(</span><span class=n>output</span><span class=p>[</span><span class=s2>&quot;embedding&quot;</span><span class=p>],</span> <span class=n>output</span><span class=p>[</span><span class=s2>&quot;mask&quot;</span><span class=p>])</span>
        <span class=k>return</span> <span class=p>{</span><span class=s2>&quot;embeddings&quot;</span><span class=p>:</span> <span class=n>embeddings</span><span class=p>,</span> <span class=s2>&quot;mask&quot;</span><span class=p>:</span> <span class=n>output</span><span class=p>[</span><span class=s2>&quot;mask&quot;</span><span class=p>]}</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=c1># And now create a TextCNN module</span>

<span class=p>[</span><span class=n>cnn</span><span class=o>-</span><span class=n>de</span><span class=o>-</span><span class=n>tpj</span><span class=p>]</span>
<span class=nd>@module</span> <span class=o>=</span> <span class=s2>&quot;cnn-de-tpj&quot;</span>
<span class=n>input_size</span> <span class=o>=</span> <span class=s2>&quot;deferred&quot;</span>


<span class=nd>@register</span><span class=p>(</span><span class=s2>&quot;text-lstm&quot;</span><span class=p>)</span>
<span class=k>class</span> <span class=nc>MyTextEncoder</span><span class=p>(</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>embedding</span><span class=p>,</span> <span class=n>kernel_sizes</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>kernel_sizes</span> <span class=o>=</span> <span class=n>kernel_sizes</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span> <span class=o>=</span> <span class=n>embedding</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>module</span> <span class=o>=</span> <span class=kc>None</span>

    <span class=k>def</span> <span class=nf>post_init</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=o>.</span><span class=n>post_init</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
        <span class=c1># We can now initialize the module</span>
        <span class=n>size</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=o>.</span><span class=n>output_size</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>text_cnn</span> <span class=o>=</span> <span class=n>TextLSTM</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>kernel_sizes</span><span class=p>,</span> <span class=n>size</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>preprocess</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>):</span>
        <span class=k>return</span> <span class=p>{</span><span class=s2>&quot;embedding&quot;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=o>.</span><span class=n>preprocess</span><span class=p>(</span><span class=n>batch</span><span class=p>)}</span>

    <span class=k>def</span> <span class=nf>collate</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>return</span> <span class=p>{</span><span class=o>...</span><span class=p>}</span>

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>):</span>
        <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=p>(</span><span class=n>batch</span><span class=p>[</span><span class=s2>&quot;embedding&quot;</span><span class=p>])</span>
        <span class=n>embeddings</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>text_cnn</span><span class=p>(</span><span class=n>output</span><span class=p>[</span><span class=s2>&quot;embedding&quot;</span><span class=p>])</span>
        <span class=k>return</span> <span class=p>{</span><span class=s2>&quot;embeddings&quot;</span><span class=p>:</span> <span class=n>embeddings</span><span class=p>}</span>
</code></pre></div> <ol> <li><strong>component-only</strong>: a TextCNN <code>Component</code> directly:</li> </ol> <div class=highlight><pre><span></span><code><span class=c1># And now create a TextCNN module</span>
<span class=k>class</span> <span class=nc>TextCNNEncoder</span><span class=p>(</span><span class=n>Component</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>embedding</span><span class=p>,</span> <span class=n>kernel_sizes</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>kernel_sizes</span> <span class=o>=</span> <span class=n>kernel_sizes</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span> <span class=o>=</span> <span class=n>embedding</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>module</span> <span class=o>=</span> <span class=kc>None</span>

    <span class=k>def</span> <span class=nf>post_init</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=o>.</span><span class=n>post_init</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
        <span class=c1># We can now initialize the CNN layers</span>
        <span class=n>size</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=o>.</span><span class=n>output_size</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>convs</span> <span class=o>=</span> <span class=o>...</span>

    <span class=k>def</span> <span class=nf>preprocess</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>):</span>
        <span class=k>return</span> <span class=p>{</span><span class=s2>&quot;embedding&quot;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=o>.</span><span class=n>preprocess</span><span class=p>(</span><span class=n>batch</span><span class=p>)}</span>

    <span class=k>def</span> <span class=nf>collate</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>return</span> <span class=p>{</span><span class=o>...</span><span class=p>}</span>

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>):</span>
        <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=p>(</span><span class=n>batch</span><span class=p>[</span><span class=s2>&quot;embedding&quot;</span><span class=p>])</span>
        <span class=k>return</span> <span class=p>{</span><span class=s2>&quot;embeddings&quot;</span><span class=p>:</span> <span class=n>reshape</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>convs</span><span class=p>(</span><span class=n>x</span><span class=p>)),</span> <span class=s2>&quot;mask&quot;</span><span class=p>:</span> <span class=n>output</span><span class=p>[</span><span class=s2>&quot;mask&quot;</span><span class=p>]}</span>
</code></pre></div> <p>We now don't need to repeat the initialization code but the module can only be used with the <code>Embedding</code> sub-component.</p> <p>3<strong>functional</strong>: same as <strong>component-only</strong> but forward code is in a function:</p> <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>apply_cnn</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>convs</span><span class=p>):</span>
    <span class=k>return</span> <span class=n>reshape</span><span class=p>(</span><span class=n>convs</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>

<span class=c1># And now create a TextCNN module</span>
<span class=k>class</span> <span class=nc>TextCNNEncoder</span><span class=p>(</span><span class=n>Component</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>embedding</span><span class=p>,</span> <span class=n>kernel_sizes</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>kernel_sizes</span> <span class=o>=</span> <span class=n>kernel_sizes</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span> <span class=o>=</span> <span class=n>embedding</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>module</span> <span class=o>=</span> <span class=kc>None</span>

    <span class=k>def</span> <span class=nf>post_init</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=o>.</span><span class=n>post_init</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
        <span class=c1># We can now initialize the CNN layers</span>
        <span class=n>size</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=o>.</span><span class=n>output_size</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>convs</span> <span class=o>=</span> <span class=o>...</span>

    <span class=k>def</span> <span class=nf>preprocess</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>):</span>
        <span class=k>return</span> <span class=p>{</span><span class=s2>&quot;embedding&quot;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=o>.</span><span class=n>preprocess</span><span class=p>(</span><span class=n>batch</span><span class=p>)}</span>

    <span class=k>def</span> <span class=nf>collate</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>return</span> <span class=p>{</span><span class=o>...</span><span class=p>}</span>

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>):</span>
        <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=p>(</span><span class=n>batch</span><span class=p>[</span><span class=s2>&quot;embedding&quot;</span><span class=p>])</span>
        <span class=k>return</span> <span class=p>{</span><span class=s2>&quot;embeddings&quot;</span><span class=p>:</span> <span class=n>apply_cnn</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>convs</span><span class=p>),</span> <span class=s2>&quot;mask&quot;</span><span class=p>:</span> <span class=n>output</span><span class=p>[</span><span class=s2>&quot;mask&quot;</span><span class=p>]}</span>
</code></pre></div> <p>We now don't need to repeat the initialization code and the forward code can only be used outside of the <code>TextCNNEncoder</code> component.</p> <p>4<strong>generic-wrapper</strong>:</p> <div class=highlight><pre><span></span><code><span class=p>[</span><span class=n>embedding</span><span class=p>]</span>

<span class=p>[</span><span class=n>base</span><span class=p>]</span>
<span class=nd>@factory</span> <span class=o>=</span> <span class=s2>&quot;trf&quot;</span>
<span class=o>...</span>

<span class=p>[</span><span class=n>encoder_1</span><span class=p>]</span>
<span class=nd>@factory</span> <span class=o>=</span> <span class=s2>&quot;cnn&quot;</span>
<span class=n>output_size</span> <span class=o>=</span> <span class=mi>12</span>

<span class=p>[</span><span class=n>span_pooler</span><span class=p>]</span>
<span class=nd>@factory</span> <span class=o>=</span> <span class=s2>&quot;span-pooler&quot;</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=k>class</span> <span class=nc>TextCNN</span><span class=p>(</span><span class=o>...</span><span class=p>):</span>
   <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>kernels_sizes</span><span class=o>=...</span><span class=p>,</span> <span class=n>output_size</span><span class=o>=...</span><span class=p>):</span>
      <span class=bp>self</span><span class=o>.</span><span class=n>kernels_sizex</span> <span class=o>=</span> <span class=o>...</span>

    <span class=k>def</span> <span class=nf>post_init</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>convs</span> <span class=o>=</span>


<span class=k>class</span> <span class=nc>EmbeddingWrapper</span><span class=p>(</span><span class=n>Component</span><span class=p>):</span>
    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>embedding</span><span class=p>,</span> <span class=n>encoders</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span> <span class=o>=</span> <span class=n>embedding</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>encoders</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>ModuleList</span><span class=p>(</span><span class=n>encoders</span><span class=p>)</span>

    <span class=k>def</span> <span class=nf>post_init</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=o>.</span><span class=n>post_init</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
        <span class=n>size</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=o>.</span><span class=n>output_size</span>
        <span class=k>for</span> <span class=n>encoder</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>encoders</span><span class=p>:</span>
            <span class=n>encoder</span><span class=o>.</span><span class=n>post_init</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=n>size</span><span class=p>)</span>
            <span class=n>size</span> <span class=o>=</span> <span class=n>encoder</span><span class=o>.</span><span class=n>output_size</span>

    <span class=k>def</span> <span class=nf>preprocess</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>):</span>
        <span class=k>return</span> <span class=p>{</span>
            <span class=s2>&quot;embedding&quot;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=o>.</span><span class=n>preprocess</span><span class=p>(</span><span class=n>batch</span><span class=p>),</span>
            <span class=o>**</span><span class=p>{</span><span class=sa>f</span><span class=s2>&quot;encoder_</span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>:</span> <span class=n>encoder</span><span class=o>.</span><span class=n>preprocess</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span> <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>encoder</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>encoders</span><span class=p>)}</span>
        <span class=p>}</span>

    <span class=k>def</span> <span class=nf>collate</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>):</span>
        <span class=k>return</span> <span class=o>...</span>

    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>):</span>
        <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=p>(</span><span class=n>batch</span><span class=p>[</span><span class=s2>&quot;embedding&quot;</span><span class=p>])</span>
        <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>encoder</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>encoders</span><span class=p>):</span>
            <span class=n>output</span> <span class=o>=</span> <span class=n>encoder</span><span class=p>({</span><span class=o>**</span><span class=n>output</span><span class=p>,</span> <span class=o>**</span><span class=n>batch</span><span class=p>[</span><span class=sa>f</span><span class=s2>&quot;encoder_</span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>]})</span>
        <span class=k>return</span> <span class=n>output</span>

    <span class=k>def</span> <span class=nf>postprocess</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>):</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=o>.</span><span class=n>postprocess</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</code></pre></div> <h3 id=anatomy-of-components>Anatomy of components</h3> <h4 id=methods>Methods</h4> <ul> <li><code>post_init</code>: called after the config has been loaded, and before the first call to <code>forward</code> to initialize the module weights with the adequate shapes (embedding layers, embedding sizes, ...)</li> <li><code>preprocess</code>: called on <code>Doc</code> objects to extract relevant features from the <code>Doc</code> objects. This means that any component that implements this method will have direct access to the <code>Doc</code> objects, and therefore is top-level.</li> <li><code>collate</code>: collates batches of <code>preprocess</code> outputs into a single batch</li> <li><code>forward</code>: called on the output of <code>collate</code> to compute the output of the component</li> <li><code>postprocess</code>: called on the output of <code>forward</code> to annotate the input <code>Doc</code> objects with the output of the component</li> </ul> <h4 id=examples>Examples:</h4> <table> <thead> <tr> <th>Component</th> <th>dynamic size</th> <th>need eg for init</th> <th>prep &amp; collate</th> <th><code>postprocess</code></th> <th>type</th> </tr> </thead> <tbody> <tr> <td><code>TransformerEncoder</code></td> <td>no</td> <td>yes (vocab)</td> <td>yes</td> <td>no</td> <td>Encoder</td> </tr> <tr> <td><code>TextCNNModule</code></td> <td>create in post_init</td> <td>no</td> <td>no</td> <td>no</td> <td>Layer</td> </tr> <tr> <td><code>TextCNNEncoder</code></td> <td>yes (prev layer)</td> <td>no</td> <td>no</td> <td>no</td> <td>Encoder</td> </tr> <tr> <td><code>SentencePooler</code></td> <td>yes (prev layer)</td> <td>maybe</td> <td>yes</td> <td>no</td> <td>Layer</td> </tr> <tr> <td><code>NER</code></td> <td>yes (prev layer)</td> <td>yes (labels)</td> <td>yes</td> <td>yes</td> <td>Component</td> </tr> <tr> <td><code>SpanClassifier</code></td> <td>yes (prev layer)</td> <td>yes (labels)</td> <td>yes</td> <td>yes</td> <td>Component</td> </tr> <tr> <td><code>SpanEmbedding</code></td> <td>yes (prev layer)</td> <td>yes (labels)</td> <td>yes</td> <td>yes</td> <td>Component</td> </tr> <tr> <td><code>LSTM</code></td> <td>yes (prev layer)</td> <td>no</td> <td>no</td> <td>yes</td> <td>Layer</td> </tr> <tr> <td><code>SpanTransformer</code></td> <td>yes (prev layer)</td> <td>maybe</td> <td>yes</td> <td>no</td> <td>Layer</td> </tr> </tbody> </table> <h4 id=classes>Classes</h4> <ul> <li><strong><code>torch.nn.Module</code></strong>: a standard PyTorch module, with a <code>forward</code> method only</li> </ul> <p>Questionnements</p> <ul> <li>premiere pipe qui calcule un embedding</li> <li>deuxieme pipe qui classifie ces embeddings</li> </ul> <h3 id=the-initialization-conundrum>The initialization conundrum</h3> <p>Imagine the following pipeline: - A tokenizer (every pipeline has one) - A sentencizer - A shared embedding layer for downstream components - A sentence classifier component</p> <p>We have a brat dataset containing sentence annotations at the entity level (one entity per sentence).</p> <p>We need: - fully annotated spaCy documents from which we will extract features to train the components - to fill missing arguments from the configuration file, such as the list of labels for the sentence classifier component.</p> <p>The problem is we might need to know which component is present in the pipeline to assign annotations on the documents and we might need documents to fill the missing components parameters.</p> <p>Plan: 1. To obtain unannotated spaCy documents, we need to know the tokenizer of the pipeline 2. Then we need to annotate (automatically using the <code>sentencizer</code> component) sentences on the documents 3. Then we need to adapt entity annotations to sentence annotations 4. Then we need to gather labels of these sentences to initialize the classifier component</p> <p>At the end of such a process, we obtain both the annotated documents and the initialized pipeline.</p> <div class=footnote><hr><ol/></div> </article> </div> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> Made with <a href="https://squidfunk.github.io/mkdocs-material/" target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": ["navigation.tracking", "navigation.instant", "navigation.indexes", "navigation.prune", "navigation.top", "content.code.annotate", "content.code.copy"], "search": "../assets/javascripts/workers/search.dfff1995.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "latest", "provider": "mike"}}</script> <script src=../assets/javascripts/bundle.dff1b7c8.min.js></script> <script src=https://cdn.jsdelivr.net/npm/vega@5></script> <script src=https://cdn.jsdelivr.net/npm/vega-lite@5></script> <script src=https://cdn.jsdelivr.net/npm/vega-embed@6></script> <script src=../assets/termynal/termynal.js></script> </body> </html>