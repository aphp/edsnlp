<!DOCTYPE html>
<html class="no-js" lang="en"> <head><meta charset="utf-8"/><meta content="width=device-width,initial-scale=1" name="viewport"/><link href="../../advanced-tutorials/fastapi/" rel="prev"/><link href="../training/" rel="next"/><link href="../../assets/logo/edsnlp.svg" rel="icon"/><meta content="mkdocs-1.5.3, mkdocs-material-9.2.8" name="generator"/><title>Deep-learning tutorial - EDS-NLP</title><link href="../../assets/stylesheets/main.046329b4.min.css" rel="stylesheet"/><link href="../../assets/stylesheets/palette.85d0ee34.min.css" rel="stylesheet"/><link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/><link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link href="../../assets/_mkdocstrings.css" rel="stylesheet"/><link href="../../assets/stylesheets/extra.css" rel="stylesheet"/><link href="../../assets/stylesheets/cards.css" rel="stylesheet"/><link href="../../assets/termynal/termynal.css" rel="stylesheet"/><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="default" dir="ltr"> <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script> <input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/> <input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/> <label class="md-overlay" for="__drawer"></label> <div data-md-component="skip"> <a class="md-skip" href="#deep-learning-tutorial"> Skip to content </a> </div> <div data-md-component="announce"> <aside class="md-banner"> <div class="md-banner__inner md-grid md-typeset"> <button aria-label="Don't show this again" class="md-banner__button md-icon"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg> </button> Check out the new <a href="../training">Model Training tutorial</a> ! </div> <script>var content,el=document.querySelector("[data-md-component=announce]");el&&(content=el.querySelector(".md-typeset"),__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0))</script> </aside> </div> <div data-md-color-scheme="default" data-md-component="outdated" hidden=""> </div> <header class="md-header md-header--shadow" data-md-component="header"> <nav aria-label="Header" class="md-header__inner md-grid"> <a aria-label="EDS-NLP" class="md-header__button md-logo" data-md-component="logo" href="../.." title="EDS-NLP"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg> </a> <label class="md-header__button md-icon" for="__drawer"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg> </label> <div class="md-header__title" data-md-component="header-title"> <div class="md-header__ellipsis"> <div class="md-header__topic"> <span class="md-ellipsis"> EDS-NLP </span> </div> <div class="md-header__topic" data-md-component="header-topic"> <span class="md-ellipsis"> Deep-learning tutorial </span> </div> </div> </div> <form class="md-header__option" data-md-component="palette"> <input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_1" name="__palette" type="radio"/> <label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to dark mode"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg> </label> <input aria-label="Switch to light mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="" data-md-color-primary="indigo" data-md-color-scheme="slate" id="__palette_2" name="__palette" type="radio"/> <label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg> </label> </form> <label class="md-header__button md-icon" for="__search"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg> </label> <div class="md-search" data-md-component="search" role="dialog"> <label class="md-search__overlay" for="__search"></label> <div class="md-search__inner" role="search"> <form class="md-search__form" name="search"> <input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/> <label class="md-search__icon md-icon" for="__search"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg> </label> <nav aria-label="Search" class="md-search__options"> <button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" title="Clear" type="reset"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg> </button> </nav> </form> <div class="md-search__output"> <div class="md-search__scrollwrap" data-md-scrollfix=""> <div class="md-search-result" data-md-component="search-result"> <div class="md-search-result__meta"> Initializing search </div> <ol class="md-search-result__list" role="presentation"></ol> </div> </div> </div> </div> </div> <div class="md-header__source"> <a class="md-source" data-md-component="source" href="https://github.com/aphp/edsnlp" title="Go to repository"> <div class="md-source__icon md-icon"> <svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!-- Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg> </div> <div class="md-source__repository"> aphp/edsnlp </div> </a> </div> </nav> </header> <div class="md-container" data-md-component="container"> <main class="md-main" data-md-component="main"> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation"> <div class="md-sidebar__scrollwrap"> <div class="md-sidebar__inner"> <nav aria-label="Navigation" class="md-nav md-nav--primary" data-md-level="0"> <label class="md-nav__title" for="__drawer"> <a aria-label="EDS-NLP" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="EDS-NLP"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg> </a> EDS-NLP </label> <div class="md-nav__source"> <a class="md-source" data-md-component="source" href="https://github.com/aphp/edsnlp" title="Go to repository"> <div class="md-source__icon md-icon"> <svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!-- Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg> </div> <div class="md-source__repository"> aphp/edsnlp </div> </a> </div> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../.."> <span class="md-ellipsis"> Getting started </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="https://aphp.github.io/edsnlp/demo" target="_blank"> <span class="md-ellipsis"> Demo </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input checked="" class="md-nav__toggle md-toggle" id="__nav_3" type="checkbox"/> <div class="md-nav__link md-nav__container"> <a class="md-nav__link" href="../"> <span class="md-ellipsis"> Tutorials </span> </a> <label class="md-nav__link" for="__nav_3"> <span class="md-nav__icon md-icon"></span> </label> </div> <nav aria-expanded="true" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1"> <label class="md-nav__title" for="__nav_3"> <span class="md-nav__icon md-icon"></span> Tutorials </label> <ul class="md-nav__list" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="../"> <span class="md-ellipsis"> Overview </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../spacy101/"> <span class="md-ellipsis"> SpaCy representations </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../matching-a-terminology/"> <span class="md-ellipsis"> Matching a terminology </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../qualifying-entities/"> <span class="md-ellipsis"> Qualifying entities </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../visualization/"> <span class="md-ellipsis"> Visualization </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../detecting-dates/"> <span class="md-ellipsis"> Detecting dates </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../reason/"> <span class="md-ellipsis"> Detecting Reason of Hospitalisation </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../endlines/"> <span class="md-ellipsis"> Detecting end-of-lines </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../aggregating-results/"> <span class="md-ellipsis"> Aggregating results </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../multiple-texts/"> <span class="md-ellipsis"> Processing multiple texts </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../advanced-tutorials/fastapi/"> <span class="md-ellipsis"> Deploying as an API </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/> <label class="md-nav__link md-nav__link--active" for="__toc"> <span class="md-ellipsis"> Deep-learning tutorial </span> <span class="md-nav__icon md-icon"></span> </label> <a class="md-nav__link md-nav__link--active" href="./"> <span class="md-ellipsis"> Deep-learning tutorial </span> </a> <nav aria-label="Table of contents" class="md-nav md-nav--secondary"> <label class="md-nav__title" for="__toc"> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="#step-by-step-walkthrough"> Step-by-step walkthrough </a> <nav aria-label="Step-by-step walkthrough" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#1-defining-the-model"> 1. Defining the model </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#2-loading-the-raw-dataset-and-convert-it-into-doc-objects"> 2. Loading the raw dataset and convert it into Doc objects </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#3-complete-the-initialization-of-the-model"> 3. Complete the initialization of the model </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#4-making-the-stream-of-mini-batches"> 4. Making the stream of mini-batches </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#5-the-training-loop"> 5. The training loop </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#6-optimizing-the-weights"> 6. Optimizing the weights </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#7-evaluating-the-model"> 7. Evaluating the model </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#full-example"> Full example </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#configuration"> Configuration </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#going-further"> Going further </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../training/"> <span class="md-ellipsis"> Training API </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../tuning/"> <span class="md-ellipsis"> Hyperparameter Tuning </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class="md-nav__link" href="../../pipes/"> <span class="md-ellipsis"> Pipes </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../tokenizers/"> <span class="md-ellipsis"> Tokenizers </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class="md-nav__link" href="../../data/"> <span class="md-ellipsis"> Data Connectors </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class="md-nav__link" href="../../concepts/pipeline/"> <span class="md-ellipsis"> Concepts </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class="md-nav__link" href="../../utilities/"> <span class="md-ellipsis"> Utilities </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class="md-nav__link" href="../../reference/edsnlp/"> <span class="md-ellipsis"> Code Reference </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../contributing/"> <span class="md-ellipsis"> Contributing to EDS-NLP </span> </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="../../changelog/"> <span class="md-ellipsis"> Changelog </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc"> <div class="md-sidebar__scrollwrap"> <div class="md-sidebar__inner"> <nav aria-label="Table of contents" class="md-nav md-nav--secondary"> <label class="md-nav__title" for="__toc"> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix=""> <li class="md-nav__item"> <a class="md-nav__link" href="#step-by-step-walkthrough"> Step-by-step walkthrough </a> <nav aria-label="Step-by-step walkthrough" class="md-nav"> <ul class="md-nav__list"> <li class="md-nav__item"> <a class="md-nav__link" href="#1-defining-the-model"> 1. Defining the model </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#2-loading-the-raw-dataset-and-convert-it-into-doc-objects"> 2. Loading the raw dataset and convert it into Doc objects </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#3-complete-the-initialization-of-the-model"> 3. Complete the initialization of the model </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#4-making-the-stream-of-mini-batches"> 4. Making the stream of mini-batches </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#5-the-training-loop"> 5. The training loop </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#6-optimizing-the-weights"> 6. Optimizing the weights </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#7-evaluating-the-model"> 7. Evaluating the model </a> </li> </ul> </nav> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#full-example"> Full example </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#configuration"> Configuration </a> </li> <li class="md-nav__item"> <a class="md-nav__link" href="#going-further"> Going further </a> </li> </ul> </nav> </div> </div> </div> <div class="md-content" data-md-component="content"> <article class="md-content__inner md-typeset"> <h1 id="deep-learning-tutorial">Deep-learning tutorial</h1> <p>In this tutorial, we'll see how we can write our own deep learning model training script with EDS-NLP. We will implement a script to train a named-entity recognition (NER) model.</p> <p>If you do not care about the details and just want to train a model, we suggest you to use the <a href="../training">training API</a> and move on to the next tutorial.</p> <div class="admonition warning"> <p class="admonition-title">Hardware requirements</p> <p>Training a modern deep learning model requires a lot of computational resources. We recommend using a machine with a GPU, ideally with at least 16GB of VRAM. If you don't have access to a GPU, you can use a cloud service like <a href="https://colab.research.google.com/">Google Colab</a>, <a href="https://www.kaggle.com/">Kaggle</a>, <a href="https://www.paperspace.com/">Paperspace</a> or <a href="https://vast.ai/">Vast.ai</a>.</p> </div> <p>Under the hood, EDS-NLP uses PyTorch to train deep-learning models. EDS-NLP acts as a sidekick to PyTorch, providing a set of tools to perform preprocessing, composition and evaluation. The trainable <a class="autorefs autorefs-internal" href="../../concepts/torch-component/#edsnlp.core.torch_component.TorchComponent"><code>TorchComponents</code></a> are actually PyTorch modules with a few extra methods to handle the feature preprocessing and postprocessing. Therefore, EDS-NLP is fully compatible with the PyTorch ecosystem.</p> <h2 id="step-by-step-walkthrough">Step-by-step walkthrough</h2> <p>Training a supervised deep-learning model consists in feeding batches of annotated samples taken from a training corpus to a model and optimizing its parameters of the model to decrease its prediction error. The process of training a pipeline with EDS-NLP is structured as follows:</p> <h3 id="1-defining-the-model">1. Defining the model</h3> <p>We first start by seeding the random states and instantiating a new trainable pipeline composed of <a href="../../pipes/trainable">trainable pipes</a>. The model described here computes text embeddings with a pre-trained transformer followed by a CNN, and performs the NER prediction task using a Conditional Random Field (CRF) token classifier.</p> <div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">edsnlp</span><span class="o">,</span><span class="w"> </span><span class="nn">edsnlp.pipes</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">eds</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">confit.utils.random</span><span class="w"> </span><span class="kn">import</span> <span class="n">set_seed</span>

<span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">edsnlp</span><span class="o">.</span><span class="n"><html><head></head><body><a class="discrete-link" href="../../reference/edsnlp/core/pipeline/#edsnlp.core.pipeline.blank">blank</a></body></html></span><span class="p">(</span><span class="s2">"eds"</span><span class="p">)</span>
<span class="n">nlp</span><span class="o">.</span><span class="n">add_pipe</span><span class="p">(</span>
    <a href="../../pipes/trainable/ner/#edsnlp.pipes.trainable.ner_crf.factory.create_component">eds.ner_crf</a><span class="p">(</span>  <span class="c1"># (1)!</span>
        <span class="n">mode</span><span class="o">=</span><span class="s2">"joint"</span><span class="p">,</span>  <span class="c1"># (2)!</span>
        <span class="n">target_span_getter</span><span class="o">=</span><span class="s2">"gold-ner"</span><span class="p">,</span>  <span class="c1"># (3)!</span>
        <span class="n">window</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">embedding</span><span class="o">=</span><a href="../../pipes/trainable/embeddings/text_cnn/#edsnlp.pipes.trainable.embeddings.text_cnn.factory.create_component">eds.text_cnn</a><span class="p">(</span>  <span class="c1"># (4)!</span>
            <span class="n">kernel_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
            <span class="n">embedding</span><span class="o">=</span><a href="../../pipes/trainable/embeddings/transformer/#edsnlp.pipes.trainable.embeddings.transformer.factory.create_component">eds.transformer</a><span class="p">(</span>  <span class="c1"># (5)!</span>
                <span class="n">model</span><span class="o">=</span><span class="s2">"prajjwal1/bert-tiny"</span><span class="p">,</span>  <span class="c1"># (6)!</span>
                <span class="n">window</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                <span class="n">stride</span><span class="o">=</span><span class="mi">96</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">),</span>
    <span class="p">),</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">"ner"</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div> <ol> <li>We use the <code><a href="../../pipes/trainable/ner/#edsnlp.pipes.trainable.ner_crf.factory.create_component">eds.ner_crf</a></code> NER task module, which classifies word embeddings into NER labels (BIOUL scheme) using a CRF.</li> <li>Each component of the pipeline can be configured with a dictionary, using the parameter described in the component's page.</li> <li>The <code>target_span_getter</code> parameter defines the name of the span group used to train the NER model. In this case, the model will look for the entities to train on in <code>doc.spans["gold-ner"]</code>. This is important because we might store entities in other span groups with a different purpose (e.g. <code>doc.spans["sections"]</code> contain the sections Spans, but we don't want to train on these). We will need to make sure the entities from the training dataset are assigned to this span group (next section).</li> <li>The word embeddings used by the CRF are computed by a CNN, which builds on top of another embedding layer.</li> <li>The base embedding layer is a pretrained transformer, which computes contextualized word embeddings.</li> <li>We chose the <code>prajjwal1/bert-tiny</code> model in this tutorial for testing purposes, but we recommend using a larger model like <code>bert-base-cased</code> or <code>camembert-base</code> (French) for real-world applications.</li> </ol> <h3 id="2-loading-the-raw-dataset-and-convert-it-into-doc-objects">2. Loading the raw dataset and convert it into Doc objects</h3> <p>To train a pipeline, we must convert our annotated data into <code>Doc</code> objects that will be either used as training samples or evaluation samples. We will assume the dataset is in <a href="../../data/standoff">Standoff format</a>, usually produced by the <a href="https://brat.nlplab.org">Brat</a> annotation tool, but any format can be used.</p> <p>At this step, we might also want to perform data augmentation, filtering, splitting or any other data transformation. In this tutorial, we will split on line jumps and filter out empty documents from the training data. We will use our <a class="autorefs autorefs-internal" href="../../concepts/inference/#edsnlp.core.stream.Stream">Stream</a> API to handle the data processing, but you can use any method you like, so long as you end up with a collection of <code>Doc</code> objects.</p> <div class="no-check highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">edsnlp</span>


<span class="k">def</span><span class="w"> </span><span class="nf">skip_empty_docs</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">doc</span>


<span class="n">training_data</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">edsnlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n"><html><head></head><body><a class="discrete-link" href="../../data/standoff/#edsnlp.data.standoff.read_standoff">read_standoff</a></body></html></span><span class="p">(</span>  <span class="c1"># (1)!</span>
        <span class="n">train_data_path</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="n">nlp</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>  <span class="c1"># (2)!</span>
        <span class="n">span_setter</span><span class="o">=</span><span class="p">[</span><span class="s2">"ents"</span><span class="p">,</span> <span class="s2">"gold-ner"</span><span class="p">],</span>  <span class="c1"># (3)!</span>
    <span class="p">)</span>
    <span class="o">.</span><span class="n">map</span><span class="p">(</span><a href="../../pipes/misc/split/#edsnlp.pipes.misc.split.split.Split">eds.split</a><span class="p">(</span><span class="n">regex</span><span class="o">=</span><span class="s2">"</span><span class="se">\n\n</span><span class="s2">"</span><span class="p">))</span>  <span class="c1"># (4)!</span>
    <span class="o">.</span><span class="n">map_batches</span><span class="p">(</span><span class="n">skip_empty_docs</span><span class="p">)</span>  <span class="c1"># (5)!</span>
<span class="p">)</span>
</code></pre></div> <ol> <li>Read the data from the brat directory and convert it into Docs.</li> <li>Tokenize the training docs with the same tokenizer as the trained model</li> <li>Store the annotated Brat entities as spans in <code>doc.ents</code>, and <code>doc.spans["gold-ner"]</code></li> <li>Split the documents on line jumps.</li> <li>Filter out empty documents.</li> </ol> <p>As for the validation data, we will keep all the documents, even empty ones, to obtain representative metrics.</p> <div class="no-check highlight"><pre><span></span><code><span class="n">val_data</span> <span class="o">=</span> <span class="n">edsnlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n"><html><head></head><body><a class="discrete-link" href="../../data/standoff/#edsnlp.data.standoff.read_standoff">read_standoff</a></body></html></span><span class="p">(</span>
    <span class="n">val_data_path</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">nlp</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">span_setter</span><span class="o">=</span><span class="p">[</span><span class="s2">"ents"</span><span class="p">,</span> <span class="s2">"gold-ner"</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">val_docs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">val_data</span><span class="p">)</span>  <span class="c1"># (1)!</span>
</code></pre></div> <ol> <li>Cache the stream result into a list of <code>Doc</code></li> </ol> <h3 id="3-complete-the-initialization-of-the-model">3. Complete the initialization of the model</h3> <p>We initialize the missing or incomplete components attributes (such as label vocabularies) with the training dataset. Indeed, when defining the model, we specified the architecture of the model, but we did not specify the types of named entities that the model will predict. This can be done either</p> <ul> <li>explicitly by setting the <code>labels</code> parameter in <code><a href="../../pipes/trainable/ner/#edsnlp.pipes.trainable.ner_crf.factory.create_component">eds.ner_crf</a></code> in the <a href="#1-defining-the-model">definition</a> above,</li> <li>automatically with <code>post_init</code>: then <code><a href="../../pipes/trainable/ner/#edsnlp.pipes.trainable.ner_crf.factory.create_component">eds.ner_crf</a></code> looks in <code>doc.spans[target_span_getter]</code> of all docs in <code>training_data</code> to infer the labels.</li> </ul> <div class="no-check highlight"><pre><span></span><code><span class="n">nlp</span><span class="o">.</span><span class="n">post_init</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>
</code></pre></div> <h3 id="4-making-the-stream-of-mini-batches">4. Making the stream of mini-batches</h3> <p>The training dataset of <code>Doc</code> objects is then preprocessed into features to be fed to the model during the training loop. We will continue to use EDS-NLP's streams to handle the data processing :</p> <ul> <li> <p>We first request the training data stream to loop on the input data, since we want that each example is seen multiple times during the training until a given number of steps is reached</p> <details class="note"> <summary>Looping in EDS-NLP Streams</summary> <p>Note that in EDS-NLP, looping on a stream is always done on the input data, no matter when <code>loop()</code> is called. This means that shuffling or any further preprocessing step will be applied multiple times, each time we loop. This is usually a good thing if preprocessing contains randomness to increase the diversity of the training samples while avoiding loading multiple versions of a same document in memory. To loop after preprocessing, we can collect the stream into a list and loop on the list (<code>edsnlp.data.from_iterable(list(training_data)), loop=True</code>).</p> </details> </li> <li> <p>We shuffle the data before batching to diversify the samples in each mini-batch</p> </li> <li>We extract the features and labels required by each component (and sub-components) of the pipeline</li> <li>Finally, we group the samples into mini-batches, such that each mini-batch contains a maximum number of tokens, or any other batching criterion and assemble (or "collate") the features into tensors</li> </ul> <div class="no-check highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">edsnlp.utils.batching</span><span class="w"> </span><span class="kn">import</span> <span class="n"><html><head></head><body><a class="discrete-link" href="../../reference/edsnlp/utils/batching/#edsnlp.utils.batching.stat_batchify">stat_batchify</a></body></html></span>

<span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>  <span class="c1"># (1)!</span>
<span class="n">batches</span> <span class="o">=</span> <span class="p">(</span>
   <span class="n">training_data</span><span class="o">.</span><span class="n">loop</span><span class="p">()</span>
    <span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="s2">"dataset"</span><span class="p">)</span>  <span class="c1"># (2)!</span>
    <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">nlp</span><span class="o">.</span><span class="n">preprocess</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">"supervision"</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span>  <span class="c1"># (3)!</span>
    <span class="o">.</span><span class="n">batchify</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span> <span class="o">*</span> <span class="mi">128</span><span class="p">,</span> <span class="n">batch_by</span><span class="o">=</span><span class="n"><html><head></head><body><a class="discrete-link" href="../../reference/edsnlp/utils/batching/#edsnlp.utils.batching.stat_batchify">stat_batchify</a></body></html></span><span class="p">(</span><span class="s2">"tokens"</span><span class="p">))</span>  <span class="c1"># (4)!</span>
    <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">nlp</span><span class="o">.</span><span class="n">collate</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">"device"</span><span class="p">:</span> <span class="n">device</span><span class="p">})</span>
<span class="p">)</span>
</code></pre></div> <ol> <li>Check if a GPU is available and set the device accordingly.</li> <li>Apply shuffling to our stream. If our dataset is too large to fit in memory, instead of "dataset" we can set the shuffle batch size to "100 docs" for example, or "fragment" for parquet datasets.</li> <li>This will call the <code>preprocess_supervised</code> method of the <a class="autorefs autorefs-internal" href="../../concepts/torch-component/#edsnlp.core.torch_component.TorchComponent">TorchComponent</a> class and return a nested dictionary containing the required features and labels.</li> <li>Make batches that contain at most 32 * 128 tokens (e.g. 32 samples of 128 tokens, but this accounts samples may have different lengths). We use the <code>stat_batchify</code> function to look for a key containing <code>tokens</code> in the features <code>stats</code> sub-dictionary and add samples to the batch until the sum of the <code>*tokens*</code> stats exceeds 32 * 128.</li> </ol> <p>and that's it ! We now have a looping stream of mini-batches that we can feed to our model. For better efficiency, we can also perform this in parallel in a separate worker by setting <code>num_cpu_workers</code> to 1 or more. Note that streams in EDS-NLP are lazy, meaning that the execution has not started yet, and the data is not loaded in memory. This will only happen when we start iterating over the stream in the next section.</p> <div class="no-check highlight"><pre><span></span><code><span class="n">batches</span> <span class="o">=</span> <span class="n">batches</span><span class="o">.</span><span class="n">set_processing</span><span class="p">(</span>
   <span class="n">num_cpu_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
   <span class="n">process_start_method</span><span class="o">=</span><span class="s2">"spawn"</span>  <span class="c1"># (1)!</span>
<span class="p">)</span>
</code></pre></div> <ol> <li>Since we use a GPU, we must use the "spawn" method to create the workers. This is because the default multiprocessing "fork" method is not compatible with CUDA.</li> </ol> <h3 id="5-the-training-loop">5. The training loop</h3> <p>We instantiate a pytorch optimizer and start the training loop</p> <div class="no-check highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">itertools</span><span class="w"> </span><span class="kn">import</span> <span class="n">chain</span><span class="p">,</span> <span class="n">repeat</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="n">lr</span> <span class="o">=</span> <span class="mf">3e-4</span>
<span class="n">max_steps</span> <span class="o">=</span> <span class="mi">400</span>

<span class="c1"># Move the model to the GPU</span>
<span class="n">nlp</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span>
    <span class="n">params</span><span class="o">=</span><span class="n">nlp</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
    <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">iterator</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">batches</span><span class="p">)</span>

<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_steps</span><span class="p">),</span> <span class="s2">"Training model"</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</code></pre></div> <h3 id="6-optimizing-the-weights">6. Optimizing the weights</h3> <p>Inside the training loop, the trainable components are fed the collated batches from the dataloader by calling the <a class="autorefs autorefs-internal" href="../../concepts/torch-component/#edsnlp.core.torch_component.TorchComponent.forward"><code>TorchComponent.forward</code></a> method (via a simple call) to compute the losses. In the case we train a multitask model (not in this tutorial) and the outputs of a shared embedding are reused between components, we enable caching by wrapping this step in a cache context. The training loop is otherwise carried in a similar fashion to a standard pytorch training loop.</p> <div class="no-check highlight"><pre><span></span><code>    <span class="k">with</span> <span class="n">nlp</span><span class="o">.</span><span class="n">cache</span><span class="p">():</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">component</span> <span class="ow">in</span> <span class="n">nlp</span><span class="o">.</span><span class="n">torch_components</span><span class="p">():</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">component</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
            <span class="k">if</span> <span class="s2">"loss"</span> <span class="ow">in</span> <span class="n">output</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">+=</span> <span class="n">output</span><span class="p">[</span><span class="s2">"loss"</span><span class="p">]</span>

    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div> <h3 id="7-evaluating-the-model">7. Evaluating the model</h3> <p>Finally, the model is evaluated on the validation dataset and saved at regular intervals. We will use the <code>NerExactMetric</code> to evaluate the NER performance using Precision, Recall and F1 scores. This metric only counts an entity as correct if it matches the label and boundaries of a target entity.</p> <div class="no-check highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">edsnlp.metrics.ner</span><span class="w"> </span><span class="kn">import</span> <span class="n">NerExactMetric</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">deepcopy</span>

<span class="n">metric</span> <span class="o">=</span> <span class="n">NerExactMetric</span><span class="p">(</span><span class="n">span_getter</span><span class="o">=</span><span class="n">nlp</span><span class="o">.</span><span class="n">pipes</span><span class="o">.</span><span class="n">ner</span><span class="o">.</span><span class="n">target_span_getter</span><span class="p">)</span>

    <span class="o">...</span>
    <span class="k">if</span> <span class="p">((</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">100</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">nlp</span><span class="o">.</span><span class="n">select_pipes</span><span class="p">(</span><span class="n">enable</span><span class="o">=</span><span class="p">[</span><span class="s2">"ner"</span><span class="p">]):</span>  <span class="c1"># (1)!</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">val_docs</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">preds</span><span class="p">:</span>
                <span class="n">doc</span><span class="o">.</span><span class="n">ents</span> <span class="o">=</span> <span class="n">doc</span><span class="o">.</span><span class="n">spans</span><span class="p">[</span><span class="s2">"gold-ner"</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># (2)!</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">pipe</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>  <span class="c1"># (3)!</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">metric</span><span class="p">(</span><span class="n">val_docs</span><span class="p">,</span> <span class="n">preds</span><span class="p">))</span>

    <span class="n">nlp</span><span class="o">.</span><span class="n">to_disk</span><span class="p">(</span><span class="s2">"model"</span><span class="p">)</span>  <span class="c1">#(4)!</span>
</code></pre></div> <ol> <li>In the case we have multiple pipes in our model, we may want to selectively evaluate each pipe, thus we use the <code>select_pipes</code> method to disable every pipe except "ner".</li> <li>Clean the documents that our model will annotate</li> <li>We use the <code>pipe</code> method to run the "ner" component on the validation dataset. This method is similar to the <code>__call__</code> method of EDS-NLP components, but it is used to run a component on a list of Docs. This is also equivalent to <div class="no-check highlight"><pre><span></span><code><span class="n">preds</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">edsnlp</span><span class="o">.</span><span class="n">data</span>
   <span class="o">.</span><span class="n"><html><head></head><body><a class="discrete-link" href="../../reference/edsnlp/data/base/#edsnlp.data.base.from_iterable">from_iterable</a></body></html></span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
   <span class="o">.</span><span class="n">map_pipeline</span><span class="p">(</span><span class="n">nlp</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div></li> <li>We could also have saved the model with <code>torch.save(model, "model.pt")</code>, but <code>nlp.to_disk</code> avoids pickling and allows to inspect the model's files by saving them into a structured directory.</li> </ol> <h2 id="full-example">Full example</h2> <p>Let's wrap the training code in a function, and make it callable from the command line using <a href="https://github.com/aphp/confit">confit</a> !</p> <details class="example"> <summary>train.py</summary> <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">  1</span>
<span class="normal">  2</span>
<span class="normal">  3</span>
<span class="normal">  4</span>
<span class="normal">  5</span>
<span class="normal">  6</span>
<span class="normal">  7</span>
<span class="normal">  8</span>
<span class="normal">  9</span>
<span class="normal"> 10</span>
<span class="normal"> 11</span>
<span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Iterator</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">confit</span><span class="w"> </span><span class="kn">import</span> <span class="n">Cli</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">edsnlp</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">edsnlp.pipes</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">eds</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">edsnlp.metrics.ner</span><span class="w"> </span><span class="kn">import</span> <span class="n">NerExactMetric</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">edsnlp.utils.batching</span><span class="w"> </span><span class="kn">import</span> <span class="n"><html><head></head><body><a class="discrete-link" href="../../reference/edsnlp/utils/batching/#edsnlp.utils.batching.stat_batchify">stat_batchify</a></body></html></span>

<span class="n">app</span> <span class="o">=</span> <span class="n">Cli</span><span class="p">(</span><span class="n">pretty_exceptions_show_locals</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>


<span class="nd">@app</span><span class="o">.</span><span class="n">command</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"train"</span><span class="p">,</span> <span class="n">registry</span><span class="o">=</span><span class="n">edsnlp</span><span class="o">.</span><span class="n">registry</span><span class="p">)</span>  <span class="c1"># (1)!</span>
<span class="k">def</span><span class="w"> </span><span class="nf">train_model</span><span class="p">(</span>
    <span class="n">nlp</span><span class="p">:</span> <span class="n">edsnlp</span><span class="o">.</span><span class="n"><html><head></head><body><a class="discrete-link" href="../../concepts/pipeline/#edsnlp.core.pipeline.Pipeline">Pipeline</a></body></html></span><span class="p">,</span>
    <span class="n">train_data_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">val_data_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span> <span class="o">*</span> <span class="mi">128</span><span class="p">,</span>
    <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
    <span class="n">max_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">400</span><span class="p">,</span>
    <span class="n">num_preprocessing_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">evaluation_interval</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
<span class="p">):</span>
    <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>

    <span class="c1"># Define function to skip empty docs</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">skip_empty_docs</span><span class="p">(</span><span class="n">batch</span><span class="p">:</span> <span class="n">Iterator</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">yield</span> <span class="n">doc</span>

    <span class="c1"># Load and process training data</span>
    <span class="n">training_data</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">edsnlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n"><html><head></head><body><a class="discrete-link" href="../../data/standoff/#edsnlp.data.standoff.read_standoff">read_standoff</a></body></html></span><span class="p">(</span>
            <span class="n">train_data_path</span><span class="p">,</span>
            <span class="n">span_setter</span><span class="o">=</span><span class="p">[</span><span class="s2">"ents"</span><span class="p">,</span> <span class="s2">"gold-ner"</span><span class="p">],</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="n">nlp</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="o">.</span><span class="n">map</span><span class="p">(</span><a href="../../pipes/misc/split/#edsnlp.pipes.misc.split.split.Split">eds.split</a><span class="p">(</span><span class="n">regex</span><span class="o">=</span><span class="s2">"</span><span class="se">\n\n</span><span class="s2">"</span><span class="p">))</span>
        <span class="o">.</span><span class="n">map_batches</span><span class="p">(</span><span class="n">skip_empty_docs</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># Load validation data</span>
    <span class="n">val_data</span> <span class="o">=</span> <span class="n">edsnlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n"><html><head></head><body><a class="discrete-link" href="../../data/standoff/#edsnlp.data.standoff.read_standoff">read_standoff</a></body></html></span><span class="p">(</span>
        <span class="n">val_data_path</span><span class="p">,</span>
        <span class="n">span_setter</span><span class="o">=</span><span class="p">[</span><span class="s2">"ents"</span><span class="p">,</span> <span class="s2">"gold-ner"</span><span class="p">],</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="n">nlp</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">val_docs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">val_data</span><span class="p">)</span>

    <span class="c1"># Initialize components</span>
    <span class="n">nlp</span><span class="o">.</span><span class="n">post_init</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>

    <span class="c1"># Prepare the stream of batches</span>
    <span class="n">batches</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">training_data</span><span class="o">.</span><span class="n">loop</span><span class="p">()</span>
        <span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="s2">"dataset"</span><span class="p">)</span>
        <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">nlp</span><span class="o">.</span><span class="n">preprocess</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">"supervision"</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span>
        <span class="o">.</span><span class="n">batchify</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">batch_by</span><span class="o">=</span><span class="n"><html><head></head><body><a class="discrete-link" href="../../reference/edsnlp/utils/batching/#edsnlp.utils.batching.stat_batchify">stat_batchify</a></body></html></span><span class="p">(</span><span class="s2">"tokens"</span><span class="p">))</span>
        <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">nlp</span><span class="o">.</span><span class="n">collate</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">"device"</span><span class="p">:</span> <span class="n">device</span><span class="p">})</span>
        <span class="o">.</span><span class="n">set_processing</span><span class="p">(</span><span class="n">num_cpu_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">process_start_method</span><span class="o">=</span><span class="s2">"spawn"</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># Move the model to the GPU if available</span>
    <span class="n">nlp</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Initialize optimizer</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">nlp</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

    <span class="n">metric</span> <span class="o">=</span> <span class="n">NerExactMetric</span><span class="p">(</span><span class="n">span_getter</span><span class="o">=</span><span class="n">nlp</span><span class="o">.</span><span class="n">pipes</span><span class="o">.</span><span class="n">ner</span><span class="o">.</span><span class="n">target_span_getter</span><span class="p">)</span>

    <span class="c1"># Training loop</span>
    <span class="n">iterator</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">batches</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_steps</span><span class="p">),</span> <span class="s2">"Training model"</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="k">with</span> <span class="n">nlp</span><span class="o">.</span><span class="n">cache</span><span class="p">():</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">component</span> <span class="ow">in</span> <span class="n">nlp</span><span class="o">.</span><span class="n">torch_components</span><span class="p">():</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">component</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
                <span class="k">if</span> <span class="s2">"loss"</span> <span class="ow">in</span> <span class="n">output</span><span class="p">:</span>
                    <span class="n">loss</span> <span class="o">+=</span> <span class="n">output</span><span class="p">[</span><span class="s2">"loss"</span><span class="p">]</span>

        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># Evaluation and model saving</span>
        <span class="k">if</span> <span class="p">((</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">evaluation_interval</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">nlp</span><span class="o">.</span><span class="n">select_pipes</span><span class="p">(</span><span class="n">enable</span><span class="o">=</span><span class="p">[</span><span class="s2">"ner"</span><span class="p">]):</span>
                <span class="c1"># Clean the documents that our model will annotate</span>
                <span class="n">preds</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">val_docs</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">preds</span><span class="p">:</span>
                    <span class="n">doc</span><span class="o">.</span><span class="n">ents</span> <span class="o">=</span> <span class="n">doc</span><span class="o">.</span><span class="n">spans</span><span class="p">[</span><span class="s2">"gold-ner"</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">preds</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">pipe</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">metric</span><span class="p">(</span><span class="n">val_docs</span><span class="p">,</span> <span class="n">preds</span><span class="p">))</span>

            <span class="n">nlp</span><span class="o">.</span><span class="n">to_disk</span><span class="p">(</span><span class="s2">"model"</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
    <span class="n">nlp</span> <span class="o">=</span> <span class="n">edsnlp</span><span class="o">.</span><span class="n"><html><head></head><body><a class="discrete-link" href="../../reference/edsnlp/core/pipeline/#edsnlp.core.pipeline.blank">blank</a></body></html></span><span class="p">(</span><span class="s2">"eds"</span><span class="p">)</span>
    <span class="n">nlp</span><span class="o">.</span><span class="n">add_pipe</span><span class="p">(</span>
        <a href="../../pipes/trainable/ner/#edsnlp.pipes.trainable.ner_crf.factory.create_component">eds.ner_crf</a><span class="p">(</span>
            <span class="n">mode</span><span class="o">=</span><span class="s2">"joint"</span><span class="p">,</span>
            <span class="n">target_span_getter</span><span class="o">=</span><span class="s2">"gold-ner"</span><span class="p">,</span>
            <span class="n">window</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
            <span class="n">embedding</span><span class="o">=</span><a href="../../pipes/trainable/embeddings/text_cnn/#edsnlp.pipes.trainable.embeddings.text_cnn.factory.create_component">eds.text_cnn</a><span class="p">(</span>
                <span class="n">kernel_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
                <span class="n">embedding</span><span class="o">=</span><a href="../../pipes/trainable/embeddings/transformer/#edsnlp.pipes.trainable.embeddings.transformer.factory.create_component">eds.transformer</a><span class="p">(</span>
                    <span class="n">model</span><span class="o">=</span><span class="s2">"prajjwal1/bert-tiny"</span><span class="p">,</span>
                    <span class="n">window</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                    <span class="n">stride</span><span class="o">=</span><span class="mi">96</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">),</span>
        <span class="p">),</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">"ner"</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">train_model</span><span class="p">(</span>
        <span class="n">nlp</span><span class="p">,</span>
        <span class="n">train_data_path</span><span class="o">=</span><span class="s2">"my_brat_data/train"</span><span class="p">,</span>
        <span class="n">val_data_path</span><span class="o">=</span><span class="s2">"my_brat_data/val"</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span> <span class="o">*</span> <span class="mi">128</span><span class="p">,</span>
        <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">max_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">num_preprocessing_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">evaluation_interval</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div> <ol> <li>This will become useful in the next section, when we will use the configuration file to define the pipeline. If you don't want to use a configuration file, you can remove this decorator.</li> </ol> </details> <p>We can now copy the above code in a notebook and run it, or call this script from the command line:</p> <div class="highlight" data-md-color-scheme="slate"><pre><span></span><code>python train.py
</code></pre></div> <p>At the end of the training, the pipeline is ready to use since every trained component of the pipeline is self-sufficient, ie contains the preprocessing, inference and postprocessing code required to run it.</p> <h2 id="configuration">Configuration</h2> <p>To decouple the configuration and the code of our training script, let's define a configuration file where we will describe <strong>both</strong> our training parameters and the pipeline. You can either write the config of the pipeline by hand, or generate a pipeline config draft from an instantiated pipeline by running:</p> <div class="no-check highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">nlp</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">to_yaml_str</span><span class="p">())</span>
</code></pre></div> <div class="highlight"><span class="filename">config.yml</span><pre><span></span><code><span class="nt">nlp</span><span class="p">:</span>
<span class="w">  </span><span class="s">"@core"</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">"pipeline"</span>
<span class="w">  </span><span class="nt">lang</span><span class="p">:</span><span class="w"> </span><span class="s">"eds"</span>
<span class="w">  </span><span class="nt">components</span><span class="p">:</span>
<span class="w">    </span><span class="nt">ner</span><span class="p">:</span>
<span class="w">      </span><span class="s">"@factory"</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">"<a href="../../pipes/trainable/ner/#edsnlp.pipes.trainable.ner_crf.factory.create_component">eds.ner_crf</a>"</span>
<span class="w">      </span><span class="nt">mode</span><span class="p">:</span><span class="w"> </span><span class="s">"joint"</span>
<span class="w">      </span><span class="nt">target_span_getter</span><span class="p">:</span><span class="w"> </span><span class="s">"gold-ner"</span>
<span class="w">      </span><span class="nt">window</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">20</span>

<span class="w">      </span><span class="nt">embedding</span><span class="p">:</span>
<span class="w">        </span><span class="s">"@factory"</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">"<a href="../../pipes/trainable/embeddings/text_cnn/#edsnlp.pipes.trainable.embeddings.text_cnn.factory.create_component">eds.text_cnn</a>"</span>
<span class="w">        </span><span class="nt">kernel_sizes</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">3</span><span class="p p-Indicator">]</span>

<span class="w">        </span><span class="nt">embedding</span><span class="p">:</span>
<span class="w">          </span><span class="s">"@factory"</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">"<a href="../../pipes/trainable/embeddings/transformer/#edsnlp.pipes.trainable.embeddings.transformer.factory.create_component">eds.transformer</a>"</span>
<span class="w">          </span><span class="nt">model</span><span class="p">:</span><span class="w"> </span><span class="s">"prajjwal1/bert-tiny"</span>
<span class="w">          </span><span class="nt">window</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">128</span>
<span class="w">          </span><span class="nt">stride</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">96</span>

<span class="nt">train</span><span class="p">:</span>
<span class="w">  </span><span class="nt">nlp</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ nlp }</span>
<span class="w">  </span><span class="nt">train_data_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">my_brat_data/train</span>
<span class="w">  </span><span class="nt">val_data_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">my_brat_data/val</span>
<span class="w">  </span><span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${ 32 * 128 }</span>
<span class="w">  </span><span class="nt">lr</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-4</span>
<span class="w">  </span><span class="nt">max_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">400</span>
<span class="w">  </span><span class="nt">num_preprocessing_workers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">  </span><span class="nt">evaluation_interval</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">100</span>
</code></pre></div> <p>And replace the end of the script by</p> <div class="no-check highlight"><pre><span></span><code><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
    <span class="n">app</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</code></pre></div> <p>That's it ! We can now call the training script with the configuration file as a parameter, and override some of its values:</p> <div class="highlight" data-md-color-scheme="slate"><pre><span></span><code>python<span class="w"> </span>train.py<span class="w"> </span>--config<span class="w"> </span>config.cfg<span class="w"> </span>--nlp.components.ner.embedding.embedding.transformer.window<span class="o">=</span><span class="m">64</span><span class="w"> </span>--seed<span class="w"> </span><span class="m">43</span>
</code></pre></div> <h2 id="going-further">Going further</h2> <p>EDS-NLP also provides a generic training script that follows the same structure as the one we just wrote. You can learn more about in the <a href="../training">next Training API tutorial</a>.</p> <p>This tutorial gave you a glimpse of the training API of EDS-NLP. To build a custom trainable component, you can refer to the <a class="autorefs autorefs-internal" href="../../concepts/torch-component/#edsnlp.core.torch_component.TorchComponent">TorchComponent</a> class or look up the implementation of <a href="https://github.com/aphp/edsnlp/tree/master/edsnlp/pipes/trainable">some of the trainable components on GitHub</a>.</p> <p>We also recommend looking at an existing project as a reference, such as <a href="https://github.com/aphp/eds-pseudo">eds-pseudo</a> or <a href="https://github.com/percevalw/mlg-norm">mlg-norm</a>.</p> <div class="footnote"><hr/><ol></ol></div> <script async="" crossorigin="anonymous" data-category="Announcements" data-category-id="DIC_kwDOG97JnM4CkS1h" data-emit-metadata="0" data-input-position="bottom" data-lang="en" data-mapping="title" data-reactions-enabled="1" data-repo="aphp/edsnlp" data-repo-id="R_kgDOG97JnA" data-strict="0" data-theme="https://aphp.github.io/edsnlp/master/assets/stylesheets/giscus_light.css" loading="lazy" src="https://giscus.app/client.js">
</script> <script>
    var giscus = document.querySelector("script[src*=giscus]")

    // Set palette on initial load
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
        var theme = palette.color.scheme === "slate"
            ? "https://aphp.github.io/edsnlp/master/assets/stylesheets/giscus_dark.css"
            : "https://aphp.github.io/edsnlp/master/assets/stylesheets/giscus_light.css"

        // Instruct Giscus to set theme
        giscus.setAttribute("data-theme", theme)
    }

    // Register event handlers after documented loaded
    document.addEventListener("DOMContentLoaded", function () {
        var ref = document.querySelector("[data-md-component=palette]")
        ref.addEventListener("change", function () {
            var palette = __md_get("__palette")
            if (palette && typeof palette.color === "object") {
                var theme = palette.color.scheme === "slate"
                    ? "https://aphp.github.io/edsnlp/master/assets/stylesheets/giscus_dark.css"
                    : "https://aphp.github.io/edsnlp/master/assets/stylesheets/giscus_light.css"

                // Instruct Giscus to change theme
                var frame = document.querySelector(".giscus-frame")
                frame.contentWindow.postMessage(
                    {giscus: {setConfig: {theme}}},
                    "https://giscus.app"
                )
            }
        })
    })
</script> </article> </div> </div> <button class="md-top md-icon" data-md-component="top" hidden="" type="button"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"></path></svg> Back to top </button> </main> <footer class="md-footer"> <nav aria-label="Footer" class="md-footer__inner md-grid"> <a aria-label="Previous: Deploying as an API" class="md-footer__link md-footer__link--prev" href="../../advanced-tutorials/fastapi/" rel="prev"> <div class="md-footer__button md-icon"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg> </div> <div class="md-footer__title"> <span class="md-footer__direction"> Previous </span> <div class="md-ellipsis"> Deploying as an API </div> </div> </a> <a aria-label="Next: Training API" class="md-footer__link md-footer__link--next" href="../training/" rel="next"> <div class="md-footer__title"> <span class="md-footer__direction"> Next </span> <div class="md-ellipsis"> Training API </div> </div> <div class="md-footer__button md-icon"> <svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"></path></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class="md-copyright"> Made with <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank"> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class="md-dialog" data-md-component="dialog"> <div class="md-dialog__inner md-typeset"></div> </div> <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tracking", "navigation.instant", "navigation.indexes", "navigation.prune", "navigation.top", "navigation.footer", "content.code.annotate", "content.code.copy", "announce.dismiss"], "search": "../../assets/javascripts/workers/search.dfff1995.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "latest", "provider": "mike"}}</script> <script src="../../assets/javascripts/bundle.dff1b7c8.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/vega@5"></script> <script src="https://cdn.jsdelivr.net/npm/vega-lite@5"></script> <script src="https://cdn.jsdelivr.net/npm/vega-embed@6"></script> <script src="../../assets/termynal/termynal.js"></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> </body> </html>